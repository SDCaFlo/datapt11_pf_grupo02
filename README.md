![portada1](https://github.com/user-attachments/assets/f587c76e-ae57-41ea-8a08-d16770a91945)

| ![Sprint 1](https://github.com/user-attachments/assets/de7d6dae-06c1-42f1-a803-f947998a8da2) | ![Sprint 2](https://github.com/user-attachments/assets/a128a8b2-a1ff-432f-9a46-5897514b977f) | ![Sprint 3](https://github.com/user-attachments/assets/90db1e5f-6c2f-426e-800a-fc6ec490c0e9) |
|:---:|:---:|:---:|
| [Ir a Sprint 1](#sprint-1) | [Ir a Sprint 2](#sprint-2) | [Ir a Sprint 3](#sprint-3) |


### <p align="center">  ☕Proyecto: </p>
# <p align="center"> 📊 Análisis de Inversión </p>
## <p align="center"> 🥐 Coffee & Brunch Bussiness </p>

### Sprint 1
![S1 ent](https://github.com/user-attachments/assets/de5a4e28-613b-48a0-b75a-97f1d74d2177)

## 📚Índice del SPRINT 1
##### 📚Índice
| Sección                         | Enlace                           |
|--------------------------------|----------------------------------|
| **Items que tiene que tener la propuesta**          | [Equipo de trabajo](#equipo-de-trabajo) |
|                                | [Entendimiento de la situación actual](#entendimiento-de-la-situación-actual) |
|                                | [Objetivos](#objetivos)          |
|                                | [Alcance](#alcance)              |
|                   | [KPIs](#kpis)                    |
|          | [Repositorio Github](#repositorio-github) |
| **Hitos**                      |                                  |
|                         | [3KPIs](#kpis)                   |
| | [Alcance](#alcance)              |
|              | [EDA de los datos](#eda) |
|             | [Repositorio Github](#repositorio-github) |
|             | [Stack Tecnológico](#stack-tecnológico) |
|          | [Metodología de trabajo](#metodología-de-trabajo) |
|                | [Diseño detallado](#diseño-detallado) |
|        | [Cronograma general Gantt](#cronograma-general-gantt) |
| | [Análisis preliminar de calidad de datos](#análisis-preliminar-de-calidad-de-datos) |
| **Documentación:**                      |                                  |
|                                |     [Stack elegido y fundamentación](#Cronograma-general-Gantt)|
|                                |    [Flujo de trabajo](#Flujo-de-trabajo)|
 
---



# 🚀Equipo de Trabajo:
# ¿Quienes Somos? 
![portada1](https://github.com/user-attachments/assets/f587c76e-ae57-41ea-8a08-d16770a91945)

# ☕ **Datanova: Datos que Impulsan Decisiones Estratégicas**  

En **Datanova**, convertimos datos en herramientas clave para el crecimiento y la innovación. Nos complace presentar nuestra propuesta para **apoyar la expansión de su negocio**, un referente en el sector **Coffee & Brunch Business**.  

Nuestro enfoque está centrado en ayudarle a **identificar las mejores ubicaciones** para sus nuevos locales, reduciendo riesgos y maximizando el **potencial de retorno**.  

### 🎯 **Nuestra misión**  
Transformar sus objetivos en resultados concretos, aprovechando el poder de los datos para diseñar una **estrategia exitosa y sostenible**.

---
Presentación de Nuestro Equipo de Ciencia de Datos
| 📊 **Analistas de Datos** | 🛠️ **Ingenieros de Datos** | 🤖 **Ingenieros de Machine Learning** |
|---------------------------|---------------------------|--------------------------------------|
| ![Claudia y Saray](https://github.com/user-attachments/assets/a0d06cbe-f168-4d52-bb97-f430dd914db7) | ![Diana y Sergio](https://github.com/user-attachments/assets/c779c3d7-47bb-4c0a-9942-5d8d327701ee) | ![Felipe y Greta](https://github.com/user-attachments/assets/e56af139-909e-48d6-be6b-0313307f840b) |
| **Claudia Jara y Saray Pacheco** <br> Expertas en explorar, interpretar y visualizar los datos, Claudia y Saray son clave para descubrir patrones, generar insights estratégicos y presentar información clara que facilita la toma de decisiones. | **Diana Moreno y Sergio Castro** <br> Diana y Sergio se especializan en diseñar y mantener la infraestructura de datos, asegurando que la información sea accesible, eficiente y escalable para proyectos de alta complejidad. | **Felipe Dedes y Greta Combold** <br> Felipe y Greta lideran el desarrollo de modelos predictivos e implementan soluciones de machine learning que automatizan procesos y generan sistemas inteligentes con impacto real. |

## Juntos, combinamos nuestras habilidades para transformar datos en valor, aportando innovación y resultados efectivos.
***

[⬆️ Volver al índice](#índice)

*** 

![Proyecto](https://github.com/user-attachments/assets/93d73cca-802b-4e67-bbb2-eb918fc40a0b)

¨
# 🔍📊Entendimiento de la situación actual
_"El mercado de cafeterías boutique y brunch está en pleno auge. La creciente demanda por experiencias gastronómicas únicas y la búsqueda de ambientes acogedores lo convierten en un sector atractivo, pero también competitivo.
Sin embargo, los principales desafíos para la expansión incluyen:

1- **Identificar zonas con alta demanda potencial.**

2- **Evaluar la rentabilidad proyectada en cada ubicación.**

3- **Reducir riesgos asociados a la competencia y baja afluencia de público.**

A partir de estos puntos clave, hemos diseñado un análisis que responde directamente a estas inquietudes y ofrece una guía estratégica basada en datos."_

[⬆️ Volver al índice](#índice)

# 🎯✨Objetivos 
![objetivo](https://github.com/user-attachments/assets/b6f1e6bf-0da2-437a-82f3-c795e756a2d1)

###### Objetivo Específicos:
1. **Realizar un Análisis Exploratorio de los Datos disponibles en Yelp y Google maps (incluir
aquí la otra fuente de dato si aplica)**
2. **Realizar un ETL que permita integrar datos de diversas fuentes y transformarlos en una
estructura unificada.**
3. **Definir el pipeline**
4. **Realizar el despliegue de datos en nube que facilite la ingesta de datos y alimentar el
modelo de machine learning.**
5. **Desarrollar un modelo de machine learning para predecir las oportunidades de inversión
basadas en los KPIs definidos.**
6. **Elaborar un dashboard de los KPIs e información clave de consulta.**

[⬆️ Volver al índice](#índice)


# 📏🌍Alcance
![Alcance](https://github.com/user-attachments/assets/d8d2240c-31a6-4825-bafa-00d62111ada7)

Este proyecto se centra en realizar un análisis integral del mercado para apoyar la expansión estratégica del negocio 'Coffee & Brunch Business'. Consideramos los siguientes puntos clave dentro del alcance:
1. **Recopilación y procesamiento de datos provenientes de Yelp, Google Maps y otras fuentes relevantes.**
2. **Diseño e implementación de un ETL para integrar y estructurar los datos en un formato unificado.**
3. **Identificación de zonas de alto potencial mediante análisis geoespacial y evaluación de métricas clave.**
4. **Desarrollo de un modelo predictivo de machine learning para estimar oportunidades de inversión.**
5. **Creación de un dashboard interactivo para la visualización de KPIs e insights relevantes.**
Este alcance está diseñado para ofrecer resultados accionables y maximizar el retorno de inversión, alineándose con los objetivos de crecimiento del negocio.

ALCANCE Este proyecto incluirá el análisis y limpieza de datos disponibles en Yelp y Google Maps para negocios de cofee and breakfast en Estados Unidos, la elaboración de un dashboard interactivo con la visualización de datos claves y Kpi y la implementación de un modelo de machine learning para predicciones y recomendaciones sobre la expansión de este tipo de negocio.
Este proyecto no incluye la Integración en tiempo real con las plataformas Yelp o google maps, análisis de información por fuera de Estados Unidos ni tampoco estrategías de marketing de expansión que se puede desarrollar en una siguiente etapa.

[⬆️ Volver al índice](#índice)
***
![EDA](https://github.com/user-attachments/assets/43d31db9-18b7-4a81-b84e-ba1980002b48)


# 📈🔎EDA
# Análisis Exploratorio de Datos
 
Durante las primeras dos semanas, nos enfocamos en la **recopilación**, **limpieza** y **análisis de datos** provenientes de **Google Maps** y **Yelp**.  

El objetivo principal de este **Análisis Exploratorio de Datos (EDA)** fue identificar **oportunidades estratégicas** para su negocio a través de los siguientes enfoques clave:  

---

### 🚀 **1. Crecimiento**  
- Identificar **zonas** con alta concentración de la **población objetivo** y **potencial de expansión**.  

---

### 🗺️ **2. Competencia**  
- Mapear la **presencia** y **distribución** de negocios similares para evaluar la **densidad competitiva**.

---

### ⭐ **3. Factores Clave de Éxito**  
- Detectar **atributos comunes** en los negocios más exitosos, tales como:  
   - 📍 **Ubicación estratégica**  
   - 🛎️ **Características del servicio**  
   - 😊 **Nivel de satisfacción del cliente**  

---

## 📈 **Resultados y Visualizaciones**  

Presentaremos **visualizaciones claras y precisas** que mostrarán:  
1. 🗂️ Los **datos brutos** recopilados.  
2. 🧹 Los resultados tras la **limpieza y análisis**.  

Por ejemplo, destacaremos:  
- 🌟 Áreas con **mayor potencial de crecimiento**.  
- ⚠️ Zonas que presentan **riesgos** debido a la **saturación del mercado**.  

---

## 🎯 **Conclusión**  
Estas conclusiones servirán como base para **identificar las mejores oportunidades de negocio**, facilitando la toma de decisiones **estratégicas** y **rentables**. 🚀  

---

![GraficosEda1](https://github.com/user-attachments/assets/67284533-1197-48ba-bf6d-ae42bc510718)

---

## 📊 **Análisis de la Base de Datos de Yelp**  

### 🗺️ **Distribución General de Comercios**  
En la base de datos de **Yelp**, identificamos aproximadamente **150,000 comercios** ubicados en **1,416 ciudades** de **Estados Unidos**.  

🔍 Como lo muestra el **primer gráfico**, las ciudades con mayor concentración de negocios son:  
- **🏙️ Philadelphia**: 9.7%  
- **🌵 Tucson**: 6.15%  
- **🌴 Tampa**: 6%  

---

### ☕ **Negocios en las Categorías Objetivo**  
Dado que el foco del cliente está en negocios de **Coffee & Tea** y **Breakfast & Brunch**, analizamos estas categorías en detalle.  

📊 El **segundo gráfico** revela:  
- **Total de negocios**: **11,758**  
- **Ciudades analizadas**: **616 ciudades** de Estados Unidos  

### 🌟 **Ciudades con Mayor Concentración**  
Los negocios de **Coffee & Tea** y **Breakfast & Brunch** se encuentran mayormente en:  
- 🏙️ **Philadelphia**  
- 🌴 **Tampa**  
- 🎷 **New Orleans**  
- 🌵 **Tucson**  
- 🎸 **Nashville**  

🔝 **Philadelphia** se destaca como la ciudad con la **mayor cantidad de negocios** en estas categorías en todo Estados Unidos.  

---

## 🎯 **Conclusión**  
El análisis de la base de datos de **Yelp** permite identificar ciudades estratégicas para la expansión del negocio, destacando **Philadelphia** como la ciudad líder en este segmento.  

--- 


![GraficosEda2](https://github.com/user-attachments/assets/3312d2bc-cd62-4a3c-ab32-930f2de2148b)

## 📝 **Análisis de Reseñas de la Base de Datos de Yelp**  

### 🔎 **Resumen General de Reseñas**  
En la base de datos de **Yelp**, encontramos:  
- **7 millones de reseñas** escritas por los usuarios.  
- **1,147,000 reseñas** corresponden a la categoría **Coffee & Breakfast**.  

---

### 📊 **Distribución de Reseñas por Ciudades**  
El **gráfico azul** revela la concentración de reseñas por ciudad, destacando:  
- 🏙️ **Philadelphia**  
- 🎷 **New Orleans**  

Estas dos ciudades concentran la **mayor cantidad de reseñas** del dataset, lo que indica un **alto interés del público** en estos negocios en dichas ubicaciones.  

---

### 👥 **Cantidad de Usuarios con Reseñas**  
En cuanto a los **usuarios** que han dejado reseñas en negocios de **Coffee & Breakfast**, identificamos:  
- **574,000 usuarios** activos.  
- Distribuidos en **616 ciudades**.  

Las ciudades con **mayor cantidad de usuarios** son:  
- 🏙️ **Philadelphia**  
- 🌴 **Tampa**  
- 🎷 **New Orleans**  
- 🏁 **Indianápolis**  

---

## 🌟 **Conclusión**  
Los datos reafirman a **Philadelphia** como un destino **clave y estratégico** para este tipo de negocios, al concentrar tanto la **mayor cantidad de reseñas** como de **usuarios activos**.  

---

### 📌 **Puntos Destacados**  
- **Reseñas Totales**: **7M**  
- **Reseñas Coffee & Breakfast**: **1.1M**  
- **Usuarios con Reseñas**: **574K**  
- **Liderazgo por Ciudad**: 🏙️ **Philadelphia**  

---

![eda3](https://github.com/user-attachments/assets/4de48cd3-e333-4d91-94a9-bcab47b04063)

---

## 🗂️ **Análisis del Dataset de Google**  

Para el dataset de **Google**, se analizaron:  
- 📊 **2.9 millones de negocios**  
- 📝 **89.9 millones de reviews**  
- 📅 Periodo: **Abril 2002 - Septiembre 2021**  

---

### 📑 **Categorías de Análisis**  
- Se identificaron **4,461 categorías distintas**.  
- Seleccionamos las **50 categorías de comida más relevantes**, las cuales representan **más del 90%** de los reviews totales asociados a establecimientos de comida.  

---

### ☁️ **Wordcloud: Palabras Más Relevantes**  
A partir de las **50 categorías principales**, extrajimos las palabras con mayor aparición y generamos la siguiente **nube de palabras** (Wordcloud).  

🔍 Las palabras más relevantes identificadas fueron:  
- **"fast"**, **"food"**, **"takeout"**, **"pizza"**, **"coffee"**, **"cafe"**  

📝 **Interpretación**:  
Esto sugiere que la categoría **coffee** tiene una **fuerte presencia** en el mercado de comida estadounidense.  

---

### ⭐ **Rating Medio por Categoría**  
Al calcular el **rating promedio** de las categorías, observamos lo siguiente:  
- ☕ Los establecimientos asociados a **Coffee** presentan un **rating elevado**, lo que indica una **alta satisfacción del cliente**.  
- 🍟 En contraste, los locales de **comida rápida** (Fast Food) se encuentran entre los **peores calificados**.  

---

## 🎯 **Conclusión**  
El análisis destaca que los negocios de **Coffee** no solo tienen una **fuerte presencia en el mercado**, sino que también son percibidos con **alta calidad** por parte de los consumidores. En comparación, los negocios de **comida rápida** muestran una menor calificación promedio, lo que refleja oportunidades para mejorar en este segmento.  

---

![eda4](https://github.com/user-attachments/assets/676e4b8b-4fae-489f-922b-60995a8297c8)

## 📊 **Análisis de Tendencias en Coffee Shops**  

### 🗓️ **Establecimientos Únicos por Periodo**  
Tras filtrar los locales a categorías asociadas a **Coffee Shops**, evaluamos la **frecuencia trimestral** de establecimientos presentes en los reviews.  

🔍 **Hallazgos**:  
- El sector muestra una **tendencia de crecimiento constante**.  
- 📉 Se identificó un periodo de **decaída** que podría estar asociado a la **pandemia**, reflejando su impacto temporal en el sector.  

---

### ⭐ **Rating Promedio por Periodo**  
A pesar de la caída en la cantidad de establecimientos durante la pandemia:  
- 📈 El **rating promedio** de los coffee shops ha mostrado un **aumento constante** a lo largo del tiempo.  

### 🔎 **Posible Interpretación**:  
- **Competencia del sector**: La mejora en el **servicio y calidad** como respuesta a un mercado más exigente.  
- ☕ **Aceptación del público**: Mayor preferencia por este tipo de establecimientos, donde el café y el ambiente social juegan un papel importante.  

---

### 📌 **Conclusión General**  
Los términos **"coffee"** y **"shop"** destacan en el análisis, lo cual refleja:  
- ☕ La **popularidad** de las cafeterías como espacios clave para **socializar** y **trabajar**.  
- 🇺🇸 Una consistencia con la **cultura estadounidense**, donde el café ocupa un lugar **central** en la rutina diaria.  

---

## 🎯 **Relevancia para el Negocio**  
El crecimiento sostenido y la alta aceptación del público por los **coffee shops** los posicionan como una **oportunidad estratégica** para nuevos emprendimientos en el sector.  

--- 

![eda5](https://github.com/user-attachments/assets/4bfc5e7e-a217-452b-8ef3-c58ec0847875)
---

## 🗺️ **Relación entre Coffee-Shops y Densidad Poblacional**  

### 🔥 **Mapa de Calor: Distribución de Coffee-Shops**  
En el **mapa de calor** (izquierda), podemos observar la **concentración de establecimientos de coffee-shops** en Estados Unidos:  
- 📍 Mayor densidad en las **costas este y oeste**, destacando a **New York** como el estado con mayor presencia.  
- 🏜️ Menor densidad en la zona **central** del país, especialmente en estados como **Nevada**, **Wyoming** y **Montana**.  

---

### 🗺️ **Mapa Coroplético: Densidad Poblacional**  
El **mapa coroplético** (derecha), generado con datos del **United States Census Bureau**, muestra la **densidad poblacional** por condado.  

### 🔎 **Comparación Visual**  
Al comparar ambos mapas:  
- Se observa una **relación directa** entre la **densidad poblacional** y la **cantidad de coffee-shops**.  
- 📈 Las zonas con **mayor densidad de población** tienden a tener una **mayor concentración** de establecimientos.  

---

### 📉 **Análisis de Correlación**  
- El cálculo de correlación lineal arroja un valor de **0.45**, lo que indica una **relación moderada** entre ambos factores.  
- Sin embargo, esta correlación **no es lo suficientemente fuerte** como para ser un **predictor confiable** por sí sola.  

---

## 🎯 **Conclusión Estratégica**  
Para el negocio de **coffee shops**:  
- La **densidad poblacional** es un factor **importante**, pero **no definitivo**.  
- Es crucial analizar otros factores que podrían influir en la **presencia** y el **éxito** del rubro, como:  
   - 📍 **Ubicación y accesibilidad**  
   - 👥 **Perfil demográfico del consumidor**  
   - 🛠️ **Nivel de competencia local**  
   - 💼 **Tendencias de consumo y hábitos de los usuarios**  

---

[⬆️ Volver al índice](#índice)
***

 # 📊📏KPIs
![kpis](https://github.com/user-attachments/assets/f8e74e2b-6de7-46e1-aba1-1cf048d2f2ef)

# 📊 **Indicadores Clave de Desempeño (KPIs)**  

En un **mercado competitivo**, el éxito y crecimiento de un negocio dependen de **decisiones fundamentadas en datos**. Por ello, hemos diseñado un sistema de medición basado en **Indicadores Clave de Desempeño (KPIs)** que permiten **rastrear y optimizar** aspectos esenciales como:  

- 📈 **Satisfacción del cliente**  
- 🔍 **Visibilidad del negocio**  
- 🛒 **Conversión hacia compras efectivas**  

Este enfoque, sustentado en **tecnología avanzada**, asegura una gestión **estratégica y escalable**.

## ✨ **KPIs Definidos**  

 

![kpi1](https://github.com/user-attachments/assets/8c79eaa8-553e-400d-9008-ec2b9709c575)
### 📌 **KPI 1: Sentimiento  --> Meta trimestral = 5%** 
S (Crecimiento de comentarios positivos)
- **Descripción**:  
   Monitorea el **sentimiento de los comentarios** para conocer la **opinión del consumidor**. Se calcula como el **porcentaje de comentarios positivos** respecto al total de comentarios del periodo.  
- **Fórmula**:  
  
Fórmula: % de crecimiento de comentarios positivos = [(Total comentarios positivos periodo actual - Total comentarios positivos periodo anterior) / Total de comentarios positivos periodo anterior] * 100

- **Meta**: ✅ **5%**  

---

**KPI2:**
![kpi2](https://github.com/user-attachments/assets/540812b7-faa7-4730-bf84-3c2c9baa3663)
### ⭐ **KPI 2: Puntuación Promedio**  
- **Descripción**:  
   Mide el **promedio de las calificaciones** dejadas por los usuarios durante un periodo, reflejando la **satisfacción del cliente** de manera cuantitativa.  
- **Fórmula**:  
   
   \text{Puntaje promedio} = \frac{\text{Sumatoria total de puntajes del periodo}}{\text{Total de usuarios que dejaron calificación}}
   
- **Meta**: ✅ **3.8**  

---
 
**KPI3**
![kpi3](https://github.com/user-attachments/assets/8aff3c10-9e5f-4ffb-a9bd-1734c2339acc)

### 🚀 **KPI 3: Tasa de Crecimiento de las Calificaciones**  
- **Descripción**:  
   Monitorea el **crecimiento de la visibilidad** del negocio basado en el **número de reseñas** recibidas en el periodo.  
- **Fórmula**:  
   \[
   \text{Porcentaje de crecimiento de calificaciones} = \frac{\text{(Total comentarios periodo actual - Total comentarios periodo anterior)}}{\text{Total comentarios periodo anterior}} \times 100
   \]  
- **Meta**: ✅ **2%**
- ---

---

## 🎯 **Resumen**  
Estos **KPIs** nos permitirán analizar y mejorar continuamente el desempeño del negocio, asegurando una **mejor experiencia del cliente**, mayor visibilidad y un crecimiento sostenible. 🚀 


[⬆️ Volver al índice](#índice)
# Flujo de Trabajo
![flujodetrabajo](https://github.com/user-attachments/assets/4ac8390b-e59e-4262-88f3-15c2adef7525)

# 🚀Pipeline 

![Imagen de WhatsApp 2024-12-16 a las 00 10 42_c2174330](https://github.com/user-attachments/assets/d193f302-c148-41db-a7ef-e711f56f9faa)

### 🌟 **Introducción**
Este proyecto implementa un pipeline de datos **robusto y escalable** que permite la **ingestión**, **transformación**, **almacenamiento** y **visualización** de datos. Además, incluye la integración de modelos de **Machine Learning** y **control de versiones** para garantizar calidad y reproducibilidad.

---

### 🔗 **Resumen del Pipeline**
**Flujo Completo**:  
**Data Source → Transform → Warehouse → Machine Learning → Visualization.

El pipeline cubre desde la ingestón de datos hasta la visualización, automatizando tareas y garantizando eficiencia.

---

### 🛠️ **Arquitectura del Pipeline**

1. **🛠️ Local Transform (Procesamiento Local)**:
   - Herramientas: **Apache Spark**, **Python** *(pandas, matplotlib, numpy)*.
   - Actividades: Exploratory Data Analysis (**EDA**), limpieza y transformaciones iniciales.

2. **💾 Data Source (Origen de Datos)**:
   - Fuentes de datos:
     - **APIs**: Google Map Places 📍, Yelp Fusion 🔎.
     - Subida manual: Archivos **CSV**, **JSON**.

3. **📈 Transform (Transformación de Datos)**:
   - **BigQuery** 📂: Almacenamiento y consulta SQL.
   - **Cloud Dataflow** 🛠️: Procesamiento escalable y en streaming.
   - **Cloud Functions** ⚙️: Automatización de tareas adicionales con Python.
   - **Cloud Scheduler** ⏰: Programación de tareas recurrentes.

4. **🏛️ Warehouse (Almacén de Datos)**:
   - **BigQuery** 📁: Actúa como **Data Warehouse** central.

5. **🤖 Machine Learning**:
   - Modelado con:
     - **TensorFlow** 💡 y **Scikit-learn** 🔬.
   - Despliegue con **Streamlit** 📺 para interfaces interactivas.

6. **📊 Visualization (Visualización de Datos)**:
   - Herramienta: **Power BI** 🔍.
   - Propósito: Dashboards interactivos para el análisis y presentación de resultados.

7. **🔒 Version Control (Control de Versiones)**:
   - **Git** ⚒️ y **GitHub** 💼: Control de versiones y colaboración.
   - **GitHub Actions** ⏳: Automatización de CI/CD.

---

### 🔄 **Flujo del Pipeline**
1. **💡 Ingestión de Datos**:
   - Datos obtenidos de **APIs** o subida manual.
2. **🛠️ Transformación Local**:
   - EDA y limpieza con **Apache Spark** y **Python**.
3. **💾 Carga a la Nube**:
   - Datos subidos a **BigQuery**.
4. **🛠️ Transformación en la Nube**:
   - Procesamiento con **Cloud Dataflow** y automatización con **Cloud Functions** y **Scheduler**.
5. **📁 Almacenamiento**:
   - Datos transformados almacenados en **BigQuery**.
6. **🤖 Machine Learning**:
   - Entrenamiento de modelos con **TensorFlow/Scikit-learn**.
   - Visualización de resultados con **Streamlit**.
7. **📊 Visualización Final**:
   - Dashboards interactivos con **Power BI**.
8. **⚒️ Control de Versiones**:
   - Automatización y control con **Git**, **GitHub** y **GitHub Actions**.

---

### 🧰 **Tecnologías Principales**
- **BigQuery** 📂: Almacenamiento y consulta de datos.
- **Cloud Dataflow** 🛠️: Procesamiento escalable.
- **TensorFlow / Scikit-learn** 🤖: Modelado de datos.
- **Streamlit** 📺: Interfaces interactivas.
- **Power BI** 🔍: Visualización de resultados.
- **Git / GitHub** 💼: Versionado y CI/CD.
- **APIs**: Google Map Places 📍, Yelp Fusion 🔎.


---



### 🚀 **Este pipeline está diseñado para ser escalable, automatizado y fácil de usar**. 🚀



[⬆️ Volver al índice](#índice)

## 🛠️🧩💻**Stack Tecnológico**
![Imagen de WhatsApp 2024-12-16 a las 00 10 03_fe20ce49](https://github.com/user-attachments/assets/af9c2744-54a6-4e46-8c52-76dd7cdc3892)

El pipeline utiliza un **stack de herramientas escalable** y eficiente:

### ⚙️ **Procesamiento de Datos**:
- **Apache Spark** 🛠️: Procesamiento distribuido.
- **Python** ✨: Lenguaje principal.
   - Bibliotecas: **pandas**, **numpy**, **matplotlib**.

### 📂 **Almacenamiento en la Nube**:
- **BigQuery**: Data Warehouse.
- **Cloud Dataflow**: Procesamiento escalable.
- **Cloud Functions**: Automatización.
- **Cloud Scheduler**: Programación de tareas.

### 🤖 **Machine Learning**:
- **TensorFlow / Scikit-learn**: Desarrollo y evaluación de modelos.
- **Streamlit**: Interfaces interactivas.

### 📊 **Visualización**:
- **Power BI**: Dashboards y análisis.

### ⚒️ **Control de Versiones**:
- **Git y GitHub**: Versionado del código.
- **GitHub Actions**: Automatización CI/CD.

### 💾 **Ingestión de Datos**:
- **APIs**: Google Map Places, Yelp Fusion.

---

### 🎯 **Beneficios del Stack**
- ✨ **Escalabilidad**: Manejo eficiente de grandes volúmenes.
- 🔄 **Automatización**: Menos procesos manuales.
- 🔒 **Reproducibilidad**: Versionado con Git/GitHub.
- 📺 **Interactividad**: Visualización clara con Streamlit y Power BI.

---

## 📝🧩 Metodología de trabajo
![metodologia](https://github.com/user-attachments/assets/4d93aefb-f479-44cf-ae86-00d417c53cdc)

Para **organizar nuestro trabajo** y **dirigir nuestros esfuerzos** hacia nuestras metas, hemos elegido trabajar con **metodologías ágiles** bajo el marco de trabajo **SCRUM** 🚀.

Este enfoque nos permite:

- ✅ **Mejorar la organización de tareas**: Asignando responsabilidades claras y manejando tiempos eficientemente.  
- 🤝 **Fomentar la colaboración**: Promoviendo la comunicación constante y el trabajo en equipo.  
- 🔄 **Adaptarnos rápidamente a los cambios**: Flexibilidad ante nuevas necesidades o retos del proyecto.  
- 📦 **Asegurar entregas continuas**: Iteraciones incrementales que mantienen el producto alineado con nuestros objetivos.\n\nTrabajar bajo **SCRUM** nos garantiza un flujo de trabajo **transparente**, **eficiente** y **enfocado en la entrega de valor**, permitiendo la mejora continua durante todo el desarrollo.

---

[⬆️ Volver al índice](#índice)

## ⏳📅Cronograma General Gantt

![gantt](https://github.com/user-attachments/assets/e9c25815-c014-4e27-86af-31defa961134)

El cronograma general del proyecto se detalla a continuación, dividido en secciones como inicio, análisis, desarrollo y finalización. Utilizamos un diagrama de Gantt para visualizar el progreso de cada tarea.

```mermaid
gantt
    title Cronograma General del Proyecto
    dateFormat  YYYY-MM-DD
    axisFormat  %d-%b

    section Sprint 1 📝
    Contextualizar la problemática    :done, b1, 2024-12-02, 2d
    Definiciones de objetivos y alcance  :done, a2, 2024-12-04, 1d
    Comprender los datos disponibles  :done, a2, 2024-12-04, 2d
    Definición de Stack Tecnológico  :done, a2, 2024-12-05, 3d
    EDA y ETL inicial  :done, a2, 2024-12-05, 6d
    Definición y KPIs  :done, a2, 2024-12-10, 1d
    Preparación y ensayo de presentación :crit, a2, 2024-12-10, 4d
    section Sprint 2 🚀
    ETL completo  (16-19 Dic)    :b1, 2024-12-16, 3d
    Pipeline y automatización (18-21 Dic)           :b2, 2024-12-18, 3d
    Diseño del Datawarehouse (18-22 Dic)        :b2, 2024-12-18, 5d
    Diseño del modelo ER (22 Dic)         :b2, 2024-12-22, 1d
    MVP Machine Learning  (06-09 Ene)       :b2, 2025-01-06, 3d
    Documentación (06-10 Ene)       :b2, 2025-01-06, 4d
    Preparación y Ensayo(09-11 Ene)   :b2, 2025-01-09, 2d
    section Sprint 3 🎯
    Diseño de Reportes/Dashboards           :c1, 2025-01-13, 5d
    KPIs                  :c2, 2025-01-16, 1d
    Modelo de Machine Learning  :c2, 2025-01-13, 7d
    Documentación               :d1, 2025-01-18, 5d
    Preparación y ensayo de presentación       :d2, 2025-01-22, 4d

```

**Cronograma General: Hitos y Entregables**

"El proyecto está diseñado para ser entregado en seis semanas, con presentaciones cada dos semanas.

**Semana 1-2:**

EDA inicial con datos de Google Maps y Yelp.
Gráficos que muestren la información limpia y general.
Definición de KPIs y fórmulas, junto con las metas iniciales.

**Semana 3-4:**

Implementación de un modelo predictivo para analizar la rentabilidad de las zonas priorizadas.
Mapas interactivos que representen el análisis geoespacial.

**Semana 5-6:**
Finalización del dashboard interactivo.
Presentación de recomendaciones finales y conclusiones basadas en los KPIs.

**Hitos:**

Desarrollo de herramientas visuales.
Documentación clara del análisis.
Recomendaciones estratégicas accionables."

[⬆️ Volver al índice](#índice)

# 🔗📂Repositorio Github

  📂EDA
   
   Analisis Preliminar Google:  
      
   EDA Google: 
      
   Analisis Preliminar Yelp: 
      
   EDA Yelp:
      
  📂ETL
  
    ETL Google 
      
    ETL Yelp 
    
 📂Data
  
Google: 
 [Data Google](https://drive.google.com/drive/folders/1r-C75XM0gNzKiJPa97j-8HIiqtOzaz42)
     
Yelp: 
[Data Yelp](https://usantotomaseduco-my.sharepoint.com/personal/dianamorenoa_usantotomas_edu_co/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fdianamorenoa%5Fusantotomas%5Fedu%5Fco%2FDocuments%2FYELP%2Ddatasets&ga=1)

         
Census
      
  -- READ.ME


[⬆️ Volver al índice](#índice)

***
"Estamos convencidos de que este proyecto será el punto de partida para la expansión exitosa de su negocio. Nuestro trabajo no solo busca identificar ubicaciones rentables, sino también brindarle herramientas que faciliten decisiones basadas en datos sólidos y confiables.
Hoy le presentamos los primeros resultados de este proceso. A medida que avancemos, le mostraremos más hallazgos, siempre con la misión de maximizar su éxito en este sector tan competitivo."

### Contacto:
#### Claudia Jara Yañez:
Rol: Data Analyst

Github:https://github.com/claujara1975

Linkedin: https://www.linkedin.com/in/claudia-jara-1517361a5/

#### Saray Pacheco Ramos:
Rol: Data Analyst  

Github: https://github.com/ssaraypr

#### Sergio Castro: Limpieza y análisis del dataset Google.
Rol: Data Engineer

Github:https://github.com/SDCaFlo

LinkedIn: 
#### Diana Moreno: Limpieza y análisis del dataset Yelp.
Rol:  Data Engineer

Github: https://github.com/dianitafeliz

LinkedIn:
#### Felipe Dedes : Machine learning y despliegue.
Rol: Machine Learning Engineer

Github:https://github.com/DedesF

LinkedIn:
#### Greta Combold: Machine Learning y despliegue.
Rol: Machine Learning Engineer

Github: https://github.com/PerlaMarGreta

LinkedIn:

[⬆️ Volver al índice](#índice)
### Sprint 2 
![S2 ent](https://github.com/user-attachments/assets/52f02cc6-e0f2-46a8-9abb-ee04b9a36671)

## 📚Índice del SPRINT 2

##### 📚Índice2
| Sección                                 | Enlace                                      |
|-----------------------------------------|---------------------------------------------|
| **Elementos del ETL**                   | [ETL completo](#etl-completo)               |
|                                         | [Estructura de datos implementada](#estructura-de-datos-implementada) |
|                                         | [Pipeline ETL automatizado](#pipeline-etl-automatizado) |
|                                         | [Diseño del Modelo ER](#diseño-del-modelo-er) |
|                                         | [Pipelines para alimentar el DW](#pipelines-para-alimentar-el-dw) |
|                                         | [Data Warehouse](#data-warehouse)          |
|                                         | [Automatización](#automatización)          |
|                                         | [Validación de datos](#validación-de-datos) |
|                                         | [Documentación](#documentación)            |
|                                         | [Diagrama ER detallado](#diagrama-er-detallado) |
|                                         | [Diccionario de datos](#diccionario-de-datos) |
|                                         | [Workflow detallando tecnologías](#workflow-detallando-tecnologías) |
|                                         | [Análisis de datos de muestra](#análisis-de-datos-de-muestra) |
| **Prototipos y Productos**              |                                             |
|                                         | [MVP/ Proof of Concept de producto de ML](#mvp-proof-of-concept-de-producto-de-ml) |
|                                         | [MVP/ Proof of Concept de Dashboard](#mvp-proof-of-concept-de-dashboard) |

---

### 📝 Contenidos

#### ETL completo
Descripción del proceso ETL...

#### Estructura de datos implementada
Descripción de la estructura de datos, incluyendo DW, DL, etc...

#### Pipeline ETL automatizado
Detalles sobre la automatización del pipeline ETL...

#### Diseño del Modelo ER
Diagrama detallado con tablas, PK, FK y tipos de datos...
"Modelo Entidad Relación ER"

"En la imagen que vemos aquí, tenemos un modelo ER que representa un sistema de análisis de datos para negocios, usuarios y reseñas, relacionadas. Vamos a desglosarlo brevemente:
Entidad central: business
Representa los negocios registrados. Contiene información como el nombre, dirección, ciudad, estado, coordenadas, categorías y atributos específicos del negocio.
Está relacionada con varias entidades secundarias.
Entidades relacionadas:
reviews: Almacena reseñas hechas por usuarios, asociadas tanto a negocios como a usuarios específicos. Incluye el texto, calificaciones y otros detalles como utilidad y humor.
user: Representa a los usuarios del sistema, con atributos como su nombre, número de reseñas, y promedio de estrellas.
checkin: Registra las visitas realizadas a los negocios, con fechas específicas.
tip: Incluye consejos o comentarios breves hechos por usuarios, vinculados a negocios.
sales: Contiene información de ventas por trimestre y año, relacionada con los negocios.
google_misc: Agrega información complementaria proveniente de Google, asociada a cada negocio.
population_per_state: Proporciona datos de población por estado y año, útil para análisis demográficos.
"El tipo de modelo que vemos aquí es un modelo de copo de nieve. Este enfoque organiza los datos de manera que las entidades están normalizadas, lo que significa que se separan en tablas más pequeñas y específicas, reduciendo redundancias.

 La estructura de datos que diseñamos no solo organiza la información, sino que también optimiza la velocidad y precisión del análisis. 


#### Pipelines para alimentar el DW
Cómo se alimenta el Data Warehouse...

#### Data Warehouse
Descripción del DW implementado...

#### Automatización
Descripción de los procesos automatizados...

#### Validación de datos
Cómo se validaron los datos...

#### Documentación
Documentación técnica sobre el proceso...

#### Diagrama ER detallado
Detalles del diagrama ER...

#### Diccionario de datos
Diccionario con descripción de las tablas, campos y datos...

#### Workflow detallando tecnologías
Tecnologías usadas y su flujo de trabajo...

#### Análisis de datos de muestra
Ejemplo de análisis de datos realizado...

#### MVP/ Proof of Concept de producto de ML
"Hemos estado desarrollando un modelo de Machine Learning para predecir el crecimiento económico de negocios de café en función de datos clave como las reseñas de los clientes, las ventas mensuales, y la ubicación de los negocios. El modelo se entrena utilizando datos históricos de ventas y valoraciones, con el objetivo de estimar el porcentaje de crecimiento de las ventas en los próximos meses. Para ello, se utilizó un RandomForestRegressor, que identifica patrones entre las características de cada negocio y su desempeño.
Además, hemos creado una interfaz interactiva utilizando Streamlit, que permite a los usuarios visualizar los resultados de las predicciones de manera clara y accesible. A través de un mapa interactivo, los usuarios pueden explorar negocios de café filtrados por ubicación, reseñas, ventas y otras variables relevantes. La interfaz permite ingresar una dirección y obtener una lista de negocios cercanos, junto con su predicción de crecimiento. Además, se incluyen filtros personalizables para ajustar la predicción a diferentes necesidades.
Este sistema no solo realiza predicciones, sino que también proporciona información práctica para ayudar a los usuarios a tomar decisiones informadas sobre la ubicación de sus negocios y su potencial de crecimiento. Con la integración de BigQuery y el uso de un modelo entrenado previamente, hemos optimizado el proceso para ofrecer resultados rápidos y precisos, con un diseño intuitivo que facilita la interpretación de los datos.

#### MVP/ Proof of Concept de Dashboard
Podemos visualizar aspectos claves como:
El comportamiento de los Kpis definidos y su cumplimiento en un panel interactivo.
Se identifica facilmente con un código de color rojo o verde el cumpliemiento del indicador, además en este panel podemos observar la tendencia de los resultados a través de los años.
Aquí podemos observar los resultados del nuevo KPI de Incremento en Ventas (+4%).
Podemos hacer filtros por años y también por alguna ubicación geográfica deseada.
Al aplicar filtros,  podemos ver información importante, como cantidad de negocios, ciudades y la ciudad con más negocios.

Al ir a cada sección por temática podemos identificar datos representativos.
En reseñas veremos una evolución de la cantidad de reseñas y los resultados del KPI de reseñas en su detalle trimestral a nivel histórico, lo que nos permite observar fácilmente el comportamiento de esta variable. Podemos ver el ranking de ciudades con más reseñas, información que es muy importante y está asociada con nuestro KPI, ya que nos indica aquellas ciudades donde podemos hacer más gestión de nuestra marca, al haber más reseñas del tipo de negocios coffee shops and breakfast  podemos obtener más clientes interesados, así mismo podemos ver una distribución geográfica de las reseñas, permitiéndonos ver muy visualmente esos estados y ciudades  donde se concentran las reseñas.
En puntaje podemos ver la evolución de los puntajes promedio, observaremos la distribución de las estrellas en las ciudad con más negocios de tipo coffee shop and breakfast, así estaremos identificando esas ubicaciones geográficas que son propensas a recibir más puntuaciones, y por lo tanto, más clientes.
Podemos hacer filtros para validar por año y por estado, también interactuando con los graficos podemos hacer filtros en los datos utilizando las opciones interactivas de Power BI
Finalmente en la página de ubicaciones podemos ver la concentración de estrellas de los negocios coffee shop and breakfast en el mapa de Estados Unidos, podemos hacer filtros si queremos conocer esas ubicaciones donde estos negocios reciben menos estrellas y donde reciben más.
Estas interacciones nos permiten correlacionar variables para realizar análisis más profundos.
Por ejemplo Si vemos Chicago es la ciudad con mejor puntuación promedio con un 4,3 pero es la última en top de ciudad con más negocios, esta tiene 492 negocios objetivo en total, mientras que New York, la ciudad con más negocios, 1.810 en total, tienen un puntaje promedio de 4,16; solo 1,3 puntos porcentuales por debajo de Chicago; esto sugiere que tener una gran cantidad de negocios no garantiza automáticamente una alta puntuación y muy probablemente otros factores deben estar influyendo en la puntuación promedio de cada ciudad, puede que en Chicago ofrecen un nivel de servicio o producto superior, lo que se traduce en una mejor percepción por parte de los clientes o ciudades más grandes como Nueva York pueden tener una mayor diversidad de negocios y, por lo tanto, una mayor variabilidad en la calidad. Esto nos invita a realizar análisis más profundos.
Este dashboard es un prototipo totalmente funcional, que ya se encuentra conectado directamente con el esquema en Bigquery, lo que nos permite consultar la información de forma actualizada e interactiva.


### Sprint 3
![S3 ent](https://github.com/user-attachments/assets/f0cf9987-0614-4451-97a3-158565f614e1)
# Próximo Sprint

