![portada1](https://github.com/user-attachments/assets/f587c76e-ae57-41ea-8a08-d16770a91945)

| ![Sprint 1](https://github.com/user-attachments/assets/de7d6dae-06c1-42f1-a803-f947998a8da2) | ![Sprint 2](https://github.com/user-attachments/assets/a128a8b2-a1ff-432f-9a46-5897514b977f) | ![Sprint 3](https://github.com/user-attachments/assets/90db1e5f-6c2f-426e-800a-fc6ec490c0e9) |
|:---:|:---:|:---:|
| [Ir a Sprint 1](#sprint-1) | [Ir a Sprint 2](#sprint-2) | [Ir a Sprint 3](#sprint-3) |


### <p align="center">  â˜•Proyecto: </p>
# <p align="center"> ğŸ“Š AnÃ¡lisis de InversiÃ³n </p>
## <p align="center"> ğŸ¥ Coffee & Brunch Bussiness </p>

### Sprint 1
![S1 ent](https://github.com/user-attachments/assets/de5a4e28-613b-48a0-b75a-97f1d74d2177)

## ğŸ“šÃndice del SPRINT 1
##### ğŸ“šÃndice
| SecciÃ³n                         | Enlace                           |
|--------------------------------|----------------------------------|
| **Items que tiene que tener la propuesta**          | [Equipo de trabajo](#equipo-de-trabajo) |
|                                | [Entendimiento de la situaciÃ³n actual](#entendimiento-de-la-situaciÃ³n-actual) |
|                                | [Objetivos](#objetivos)          |
|                                | [Alcance](#alcance)              |
|                   | [KPIs](#kpis)                    |
|          | [Repositorio Github](#repositorio-github) |
| **Hitos**                      |                                  |
|                         | [3KPIs](#kpis)                   |
| | [Alcance](#alcance)              |
|              | [EDA de los datos](#eda) |
|             | [Repositorio Github](#repositorio-github) |
|             | [Stack TecnolÃ³gico](#stack-tecnolÃ³gico) |
|          | [MetodologÃ­a de trabajo](#metodologÃ­a-de-trabajo) |
|                | [DiseÃ±o detallado](#diseÃ±o-detallado) |
|        | [Cronograma general Gantt](#cronograma-general-gantt) |
| | [AnÃ¡lisis preliminar de calidad de datos](#anÃ¡lisis-preliminar-de-calidad-de-datos) |
| **DocumentaciÃ³n:**                      |                                  |
|                                |     [Stack elegido y fundamentaciÃ³n](#Cronograma-general-Gantt)|
|                                |    [Flujo de trabajo](#Flujo-de-trabajo)|
 
---



# ğŸš€Equipo de Trabajo:
# Â¿Quienes Somos? 
![portada1](https://github.com/user-attachments/assets/f587c76e-ae57-41ea-8a08-d16770a91945)

# â˜• **Datanova: Datos que Impulsan Decisiones EstratÃ©gicas**  

En **Datanova**, convertimos datos en herramientas clave para el crecimiento y la innovaciÃ³n. Nos complace presentar nuestra propuesta para **apoyar la expansiÃ³n de su negocio**, un referente en el sector **Coffee & Brunch Business**.  

Nuestro enfoque estÃ¡ centrado en ayudarle a **identificar las mejores ubicaciones** para sus nuevos locales, reduciendo riesgos y maximizando el **potencial de retorno**.  

### ğŸ¯ **Nuestra misiÃ³n**  
Transformar sus objetivos en resultados concretos, aprovechando el poder de los datos para diseÃ±ar una **estrategia exitosa y sostenible**.

---
PresentaciÃ³n de Nuestro Equipo de Ciencia de Datos
| ğŸ“Š **Analistas de Datos** | ğŸ› ï¸ **Ingenieros de Datos** | ğŸ¤– **Ingenieros de Machine Learning** |
|---------------------------|---------------------------|--------------------------------------|
| ![Claudia y Saray](https://github.com/user-attachments/assets/a0d06cbe-f168-4d52-bb97-f430dd914db7) | ![Diana y Sergio](https://github.com/user-attachments/assets/c779c3d7-47bb-4c0a-9942-5d8d327701ee) | ![Felipe y Greta](https://github.com/user-attachments/assets/e56af139-909e-48d6-be6b-0313307f840b) |
| **Claudia Jara y Saray Pacheco** <br> Expertas en explorar, interpretar y visualizar los datos, Claudia y Saray son clave para descubrir patrones, generar insights estratÃ©gicos y presentar informaciÃ³n clara que facilita la toma de decisiones. | **Diana Moreno y Sergio Castro** <br> Diana y Sergio se especializan en diseÃ±ar y mantener la infraestructura de datos, asegurando que la informaciÃ³n sea accesible, eficiente y escalable para proyectos de alta complejidad. | **Felipe Dedes y Greta Combold** <br> Felipe y Greta lideran el desarrollo de modelos predictivos e implementan soluciones de machine learning que automatizan procesos y generan sistemas inteligentes con impacto real. |

## Juntos, combinamos nuestras habilidades para transformar datos en valor, aportando innovaciÃ³n y resultadosÂ efectivos.
***

[â¬†ï¸ Volver al Ã­ndice](#Ã­ndice)

*** 

![Proyecto](https://github.com/user-attachments/assets/93d73cca-802b-4e67-bbb2-eb918fc40a0b)

Â¨
# ğŸ”ğŸ“ŠEntendimiento de la situaciÃ³n actual
_"El mercado de cafeterÃ­as boutique y brunch estÃ¡ en pleno auge. La creciente demanda por experiencias gastronÃ³micas Ãºnicas y la bÃºsqueda de ambientes acogedores lo convierten en un sector atractivo, pero tambiÃ©n competitivo.
Sin embargo, los principales desafÃ­os para la expansiÃ³n incluyen:

1- **Identificar zonas con alta demanda potencial.**

2- **Evaluar la rentabilidad proyectada en cada ubicaciÃ³n.**

3- **Reducir riesgos asociados a la competencia y baja afluencia de pÃºblico.**

A partir de estos puntos clave, hemos diseÃ±ado un anÃ¡lisis que responde directamente a estas inquietudes y ofrece una guÃ­a estratÃ©gica basada en datos."_

[â¬†ï¸ Volver al Ã­ndice](#Ã­ndice)

# ğŸ¯âœ¨Objetivos 
![objetivo](https://github.com/user-attachments/assets/b6f1e6bf-0da2-437a-82f3-c795e756a2d1)

###### Objetivo EspecÃ­ficos:
1. **Realizar un AnÃ¡lisis Exploratorio de los Datos disponibles en Yelp y Google maps (incluir
aquÃ­ la otra fuente de dato si aplica)**
2. **Realizar un ETL que permita integrar datos de diversas fuentes y transformarlos en una
estructura unificada.**
3. **Definir el pipeline**
4. **Realizar el despliegue de datos en nube que facilite la ingesta de datos y alimentar el
modelo de machine learning.**
5. **Desarrollar un modelo de machine learning para predecir las oportunidades de inversiÃ³n
basadas en los KPIs definidos.**
6. **Elaborar un dashboard de los KPIs e informaciÃ³n clave de consulta.**

[â¬†ï¸ Volver al Ã­ndice](#Ã­ndice)


# ğŸ“ğŸŒAlcance
![Alcance](https://github.com/user-attachments/assets/d8d2240c-31a6-4825-bafa-00d62111ada7)

Este proyecto se centra en realizar un anÃ¡lisis integral del mercado para apoyar la expansiÃ³n estratÃ©gica del negocio 'Coffee & Brunch Business'. Consideramos los siguientes puntos clave dentro del alcance:
1. **RecopilaciÃ³n y procesamiento de datos provenientes de Yelp, Google Maps y otras fuentes relevantes.**
2. **DiseÃ±o e implementaciÃ³n de un ETL para integrar y estructurar los datos en un formato unificado.**
3. **IdentificaciÃ³n de zonas de alto potencial mediante anÃ¡lisis geoespacial y evaluaciÃ³n de mÃ©tricas clave.**
4. **Desarrollo de un modelo predictivo de machine learning para estimar oportunidades de inversiÃ³n.**
5. **CreaciÃ³n de un dashboard interactivo para la visualizaciÃ³n de KPIs e insights relevantes.**
Este alcance estÃ¡ diseÃ±ado para ofrecer resultados accionables y maximizar el retorno de inversiÃ³n, alineÃ¡ndose con los objetivos de crecimiento del negocio.

ALCANCE Este proyecto incluirÃ¡ el anÃ¡lisis y limpieza de datos disponibles en Yelp y Google Maps para negocios de cofee and breakfast en Estados Unidos, la elaboraciÃ³n de un dashboard interactivo con la visualizaciÃ³n de datos claves y Kpi y la implementaciÃ³n de un modelo de machine learning para predicciones y recomendaciones sobre la expansiÃ³n de este tipo de negocio.
Este proyecto no incluye la IntegraciÃ³n en tiempo real con las plataformas Yelp o google maps, anÃ¡lisis de informaciÃ³n por fuera de Estados Unidos ni tampoco estrategÃ­as de marketing de expansiÃ³n que se puede desarrollar en una siguiente etapa.

[â¬†ï¸ Volver al Ã­ndice](#Ã­ndice)
***
![EDA](https://github.com/user-attachments/assets/43d31db9-18b7-4a81-b84e-ba1980002b48)


# ğŸ“ˆğŸ”EDA
# AnÃ¡lisis Exploratorio de Datos
 
Durante las primeras dos semanas, nos enfocamos en la **recopilaciÃ³n**, **limpieza** y **anÃ¡lisis de datos** provenientes de **Google Maps** y **Yelp**.  

El objetivo principal de este **AnÃ¡lisis Exploratorio de Datos (EDA)** fue identificar **oportunidades estratÃ©gicas** para su negocio a travÃ©s de los siguientes enfoques clave:  

---

### ğŸš€ **1. Crecimiento**  
- Identificar **zonas** con alta concentraciÃ³n de la **poblaciÃ³n objetivo** y **potencial de expansiÃ³n**.  

---

### ğŸ—ºï¸ **2. Competencia**  
- Mapear la **presencia** y **distribuciÃ³n** de negocios similares para evaluar la **densidad competitiva**.

---

### â­ **3. Factores Clave de Ã‰xito**  
- Detectar **atributos comunes** en los negocios mÃ¡s exitosos, tales como:  
   - ğŸ“ **UbicaciÃ³n estratÃ©gica**  
   - ğŸ›ï¸ **CaracterÃ­sticas del servicio**  
   - ğŸ˜Š **Nivel de satisfacciÃ³n del cliente**  

---

## ğŸ“ˆ **Resultados y Visualizaciones**  

Presentaremos **visualizaciones claras y precisas** que mostrarÃ¡n:  
1. ğŸ—‚ï¸ Los **datos brutos** recopilados.  
2. ğŸ§¹ Los resultados tras la **limpieza y anÃ¡lisis**.  

Por ejemplo, destacaremos:  
- ğŸŒŸ Ãreas con **mayor potencial de crecimiento**.  
- âš ï¸ Zonas que presentan **riesgos** debido a la **saturaciÃ³n del mercado**.  

---

## ğŸ¯ **ConclusiÃ³n**  
Estas conclusiones servirÃ¡n como base para **identificar las mejores oportunidades de negocio**, facilitando la toma de decisiones **estratÃ©gicas** y **rentables**. ğŸš€  

---

![GraficosEda1](https://github.com/user-attachments/assets/67284533-1197-48ba-bf6d-ae42bc510718)

---

## ğŸ“Š **AnÃ¡lisis de la Base de Datos de Yelp**  

### ğŸ—ºï¸ **DistribuciÃ³n General de Comercios**  
En la base de datos de **Yelp**, identificamos aproximadamente **150,000 comercios** ubicados en **1,416 ciudades** de **Estados Unidos**.  

ğŸ” Como lo muestra el **primer grÃ¡fico**, las ciudades con mayor concentraciÃ³n de negocios son:  
- **ğŸ™ï¸ Philadelphia**: 9.7%  
- **ğŸŒµ Tucson**: 6.15%  
- **ğŸŒ´ Tampa**: 6%  

---

### â˜• **Negocios en las CategorÃ­as Objetivo**  
Dado que el foco del cliente estÃ¡ en negocios de **Coffee & Tea** y **Breakfast & Brunch**, analizamos estas categorÃ­as en detalle.  

ğŸ“Š El **segundo grÃ¡fico** revela:  
- **Total de negocios**: **11,758**  
- **Ciudades analizadas**: **616 ciudades** de Estados Unidos  

### ğŸŒŸ **Ciudades con Mayor ConcentraciÃ³n**  
Los negocios de **Coffee & Tea** y **Breakfast & Brunch** se encuentran mayormente en:  
- ğŸ™ï¸ **Philadelphia**  
- ğŸŒ´ **Tampa**  
- ğŸ· **New Orleans**  
- ğŸŒµ **Tucson**  
- ğŸ¸ **Nashville**  

ğŸ” **Philadelphia** se destaca como la ciudad con la **mayor cantidad de negocios** en estas categorÃ­as en todo Estados Unidos.  

---

## ğŸ¯ **ConclusiÃ³n**  
El anÃ¡lisis de la base de datos de **Yelp** permite identificar ciudades estratÃ©gicas para la expansiÃ³n del negocio, destacando **Philadelphia** como la ciudad lÃ­der en este segmento.  

--- 


![GraficosEda2](https://github.com/user-attachments/assets/3312d2bc-cd62-4a3c-ab32-930f2de2148b)

## ğŸ“ **AnÃ¡lisis de ReseÃ±as de la Base de Datos de Yelp**  

### ğŸ” **Resumen General de ReseÃ±as**  
En la base de datos de **Yelp**, encontramos:  
- **7 millones de reseÃ±as** escritas por los usuarios.  
- **1,147,000 reseÃ±as** corresponden a la categorÃ­a **Coffee & Breakfast**.  

---

### ğŸ“Š **DistribuciÃ³n de ReseÃ±as por Ciudades**  
El **grÃ¡fico azul** revela la concentraciÃ³n de reseÃ±as por ciudad, destacando:  
- ğŸ™ï¸ **Philadelphia**  
- ğŸ· **New Orleans**  

Estas dos ciudades concentran la **mayor cantidad de reseÃ±as** del dataset, lo que indica un **alto interÃ©s del pÃºblico** en estos negocios en dichas ubicaciones.  

---

### ğŸ‘¥ **Cantidad de Usuarios con ReseÃ±as**  
En cuanto a los **usuarios** que han dejado reseÃ±as en negocios de **Coffee & Breakfast**, identificamos:  
- **574,000 usuarios** activos.  
- Distribuidos en **616 ciudades**.  

Las ciudades con **mayor cantidad de usuarios** son:  
- ğŸ™ï¸ **Philadelphia**  
- ğŸŒ´ **Tampa**  
- ğŸ· **New Orleans**  
- ğŸ **IndianÃ¡polis**  

---

## ğŸŒŸ **ConclusiÃ³n**  
Los datos reafirman a **Philadelphia** como un destino **clave y estratÃ©gico** para este tipo de negocios, al concentrar tanto la **mayor cantidad de reseÃ±as** como de **usuarios activos**.  

---

### ğŸ“Œ **Puntos Destacados**  
- **ReseÃ±as Totales**: **7M**  
- **ReseÃ±as Coffee & Breakfast**: **1.1M**  
- **Usuarios con ReseÃ±as**: **574K**  
- **Liderazgo por Ciudad**: ğŸ™ï¸ **Philadelphia**  

---

![eda3](https://github.com/user-attachments/assets/4de48cd3-e333-4d91-94a9-bcab47b04063)

---

## ğŸ—‚ï¸ **AnÃ¡lisis del Dataset de Google**  

Para el dataset de **Google**, se analizaron:  
- ğŸ“Š **2.9 millones de negocios**  
- ğŸ“ **89.9 millones de reviews**  
- ğŸ“… Periodo: **Abril 2002 - Septiembre 2021**  

---

### ğŸ“‘ **CategorÃ­as de AnÃ¡lisis**  
- Se identificaron **4,461 categorÃ­as distintas**.  
- Seleccionamos las **50 categorÃ­as de comida mÃ¡s relevantes**, las cuales representan **mÃ¡s del 90%** de los reviews totales asociados a establecimientos de comida.  

---

### â˜ï¸ **Wordcloud: Palabras MÃ¡s Relevantes**  
A partir de las **50 categorÃ­as principales**, extrajimos las palabras con mayor apariciÃ³n y generamos la siguiente **nube de palabras** (Wordcloud).  

ğŸ” Las palabras mÃ¡s relevantes identificadas fueron:  
- **"fast"**, **"food"**, **"takeout"**, **"pizza"**, **"coffee"**, **"cafe"**  

ğŸ“ **InterpretaciÃ³n**:  
Esto sugiere que la categorÃ­a **coffee** tiene una **fuerte presencia** en el mercado de comida estadounidense.  

---

### â­ **Rating Medio por CategorÃ­a**  
Al calcular el **rating promedio** de las categorÃ­as, observamos lo siguiente:  
- â˜• Los establecimientos asociados a **Coffee** presentan un **rating elevado**, lo que indica una **alta satisfacciÃ³n del cliente**.  
- ğŸŸ En contraste, los locales de **comida rÃ¡pida** (Fast Food) se encuentran entre los **peores calificados**.  

---

## ğŸ¯ **ConclusiÃ³n**  
El anÃ¡lisis destaca que los negocios de **Coffee** no solo tienen una **fuerte presencia en el mercado**, sino que tambiÃ©n son percibidos con **alta calidad** por parte de los consumidores. En comparaciÃ³n, los negocios de **comida rÃ¡pida** muestran una menor calificaciÃ³n promedio, lo que refleja oportunidades para mejorar en este segmento.  

---

![eda4](https://github.com/user-attachments/assets/676e4b8b-4fae-489f-922b-60995a8297c8)

## ğŸ“Š **AnÃ¡lisis de Tendencias en Coffee Shops**  

### ğŸ—“ï¸ **Establecimientos Ãšnicos por Periodo**  
Tras filtrar los locales a categorÃ­as asociadas a **Coffee Shops**, evaluamos la **frecuencia trimestral** de establecimientos presentes en los reviews.  

ğŸ” **Hallazgos**:  
- El sector muestra una **tendencia de crecimiento constante**.  
- ğŸ“‰ Se identificÃ³ un periodo de **decaÃ­da** que podrÃ­a estar asociado a la **pandemia**, reflejando su impacto temporal en el sector.  

---

### â­ **Rating Promedio por Periodo**  
A pesar de la caÃ­da en la cantidad de establecimientos durante la pandemia:  
- ğŸ“ˆ El **rating promedio** de los coffee shops ha mostrado un **aumento constante** a lo largo del tiempo.  

### ğŸ” **Posible InterpretaciÃ³n**:  
- **Competencia del sector**: La mejora en el **servicio y calidad** como respuesta a un mercado mÃ¡s exigente.  
- â˜• **AceptaciÃ³n del pÃºblico**: Mayor preferencia por este tipo de establecimientos, donde el cafÃ© y el ambiente social juegan un papel importante.  

---

### ğŸ“Œ **ConclusiÃ³n General**  
Los tÃ©rminos **"coffee"** y **"shop"** destacan en el anÃ¡lisis, lo cual refleja:  
- â˜• La **popularidad** de las cafeterÃ­as como espacios clave para **socializar** y **trabajar**.  
- ğŸ‡ºğŸ‡¸ Una consistencia con la **cultura estadounidense**, donde el cafÃ© ocupa un lugar **central** en la rutina diaria.  

---

## ğŸ¯ **Relevancia para el Negocio**  
El crecimiento sostenido y la alta aceptaciÃ³n del pÃºblico por los **coffee shops** los posicionan como una **oportunidad estratÃ©gica** para nuevos emprendimientos en el sector.  

--- 

![eda5](https://github.com/user-attachments/assets/4bfc5e7e-a217-452b-8ef3-c58ec0847875)
---

## ğŸ—ºï¸ **RelaciÃ³n entre Coffee-Shops y Densidad Poblacional**  

### ğŸ”¥ **Mapa de Calor: DistribuciÃ³n de Coffee-Shops**  
En el **mapa de calor** (izquierda), podemos observar la **concentraciÃ³n de establecimientos de coffee-shops** en Estados Unidos:  
- ğŸ“ Mayor densidad en las **costas este y oeste**, destacando a **New York** como el estado con mayor presencia.  
- ğŸœï¸ Menor densidad en la zona **central** del paÃ­s, especialmente en estados como **Nevada**, **Wyoming** y **Montana**.  

---

### ğŸ—ºï¸ **Mapa CoroplÃ©tico: Densidad Poblacional**  
El **mapa coroplÃ©tico** (derecha), generado con datos del **United States Census Bureau**, muestra la **densidad poblacional** por condado.  

### ğŸ” **ComparaciÃ³n Visual**  
Al comparar ambos mapas:  
- Se observa una **relaciÃ³n directa** entre la **densidad poblacional** y la **cantidad de coffee-shops**.  
- ğŸ“ˆ Las zonas con **mayor densidad de poblaciÃ³n** tienden a tener una **mayor concentraciÃ³n** de establecimientos.  

---

### ğŸ“‰ **AnÃ¡lisis de CorrelaciÃ³n**  
- El cÃ¡lculo de correlaciÃ³n lineal arroja un valor de **0.45**, lo que indica una **relaciÃ³n moderada** entre ambos factores.  
- Sin embargo, esta correlaciÃ³n **no es lo suficientemente fuerte** como para ser un **predictor confiable** por sÃ­ sola.  

---

## ğŸ¯ **ConclusiÃ³n EstratÃ©gica**  
Para el negocio de **coffee shops**:  
- La **densidad poblacional** es un factor **importante**, pero **no definitivo**.  
- Es crucial analizar otros factores que podrÃ­an influir en la **presencia** y el **Ã©xito** del rubro, como:  
   - ğŸ“ **UbicaciÃ³n y accesibilidad**  
   - ğŸ‘¥ **Perfil demogrÃ¡fico del consumidor**  
   - ğŸ› ï¸ **Nivel de competencia local**  
   - ğŸ’¼ **Tendencias de consumo y hÃ¡bitos de los usuarios**  

---

[â¬†ï¸ Volver al Ã­ndice](#Ã­ndice)
***

 # ğŸ“ŠğŸ“KPIs
![kpis](https://github.com/user-attachments/assets/f8e74e2b-6de7-46e1-aba1-1cf048d2f2ef)

# ğŸ“Š **Indicadores Clave de DesempeÃ±o (KPIs)**  

En un **mercado competitivo**, el Ã©xito y crecimiento de un negocio dependen de **decisiones fundamentadas en datos**. Por ello, hemos diseÃ±ado un sistema de mediciÃ³n basado en **Indicadores Clave de DesempeÃ±o (KPIs)** que permiten **rastrear y optimizar** aspectos esenciales como:  

- ğŸ“ˆ **SatisfacciÃ³n del cliente**  
- ğŸ” **Visibilidad del negocio**  
- ğŸ›’ **ConversiÃ³n hacia compras efectivas**  

Este enfoque, sustentado en **tecnologÃ­a avanzada**, asegura una gestiÃ³n **estratÃ©gica y escalable**.

## âœ¨ **KPIs Definidos**  

 
![kpi1](https://github.com/user-attachments/assets/c8b6eb47-25c4-4440-9274-d6c68e502d87)

### ğŸ“Œ **KPI 1: Sentimiento  --> Meta trimestral = 5%** 
S (Crecimiento de comentarios positivos)
- **DescripciÃ³n**:  
   Monitorea el **sentimiento de los comentarios** para conocer la **opiniÃ³n del consumidor**. Se calcula como el **porcentaje de comentarios positivos** respecto al total de comentarios del periodo.  
- **FÃ³rmula**:  
  
FÃ³rmula: % de crecimiento de comentarios positivos = [(Total comentarios positivos periodo actual - Total comentarios positivos periodo anterior) / Total de comentarios positivos periodo anterior] * 100

- **Meta**: âœ… **5%**  

---

**KPI2:**
![kpi2](https://github.com/user-attachments/assets/540812b7-faa7-4730-bf84-3c2c9baa3663)
### â­ **KPI 2: PuntuaciÃ³n Promedio**  
- **DescripciÃ³n**:  
   Mide el **promedio de las calificaciones** dejadas por los usuarios durante un periodo, reflejando la **satisfacciÃ³n del cliente** de manera cuantitativa.  
- **FÃ³rmula**:  
   
   \text{Puntaje promedio} = \frac{\text{Sumatoria total de puntajes del periodo}}{\text{Total de usuarios que dejaron calificaciÃ³n}}
   
- **Meta**: âœ… **3.8**  

---
 
**KPI3**
![kpi3](https://github.com/user-attachments/assets/8b5408d9-84e3-4ca2-9c2b-1f9574f5b726)


### ğŸš€ **KPI 3: Tasa de Crecimiento de las Calificaciones**  
- **DescripciÃ³n**:  
   Monitorea el **crecimiento de la visibilidad** del negocio basado en el **nÃºmero de reseÃ±as** recibidas en el periodo.  
- **FÃ³rmula**:  
   \[
   \text{Porcentaje de crecimiento de calificaciones} = \frac{\text{(Total comentarios periodo actual - Total comentarios periodo anterior)}}{\text{Total comentarios periodo anterior}} \times 100
   \]  
- **Meta**: âœ… **2%**
- ---

---

## ğŸ¯ **Resumen**  
Estos **KPIs** nos permitirÃ¡n analizar y mejorar continuamente el desempeÃ±o del negocio, asegurando una **mejor experiencia del cliente**, mayor visibilidad y un crecimiento sostenible. ğŸš€ 


[â¬†ï¸ Volver al Ã­ndice](#Ã­ndice)
# Flujo de Trabajo
![flujodetrabajo](https://github.com/user-attachments/assets/4ac8390b-e59e-4262-88f3-15c2adef7525)

# ğŸš€Pipeline 

![Imagen de WhatsApp 2024-12-16 a las 00 10 42_c2174330](https://github.com/user-attachments/assets/d193f302-c148-41db-a7ef-e711f56f9faa)

### ğŸŒŸ **IntroducciÃ³n**
Este proyecto implementa un pipeline de datos **robusto y escalable** que permite la **ingestiÃ³n**, **transformaciÃ³n**, **almacenamiento** y **visualizaciÃ³n** de datos. AdemÃ¡s, incluye la integraciÃ³n de modelos de **Machine Learning** y **control de versiones** para garantizar calidad y reproducibilidad.

---

### ğŸ”— **Resumen del Pipeline**
**Flujo Completo**:  
**Data Source â†’ Transform â†’ Warehouse â†’ Machine Learning â†’ Visualization.

El pipeline cubre desde la ingestÃ³n de datos hasta la visualizaciÃ³n, automatizando tareas y garantizando eficiencia.

---

### ğŸ› ï¸ **Arquitectura del Pipeline**

1. **ğŸ› ï¸ Local Transform (Procesamiento Local)**:
   - Herramientas: **Apache Spark**, **Python** *(pandas, matplotlib, numpy)*.
   - Actividades: Exploratory Data Analysis (**EDA**), limpieza y transformaciones iniciales.

2. **ğŸ’¾ Data Source (Origen de Datos)**:
   - Fuentes de datos:
     - **APIs**: Google Map Places ğŸ“, Yelp Fusion ğŸ”.
     - Subida manual: Archivos **CSV**, **JSON**.

3. **ğŸ“ˆ Transform (TransformaciÃ³n de Datos)**:
   - **BigQuery** ğŸ“‚: Almacenamiento y consulta SQL.
   - **Cloud Dataflow** ğŸ› ï¸: Procesamiento escalable y en streaming.
   - **Cloud Functions** âš™ï¸: AutomatizaciÃ³n de tareas adicionales con Python.
   - **Cloud Scheduler** â°: ProgramaciÃ³n de tareas recurrentes.

4. **ğŸ›ï¸ Warehouse (AlmacÃ©n de Datos)**:
   - **BigQuery** ğŸ“: ActÃºa como **Data Warehouse** central.

5. **ğŸ¤– Machine Learning**:
   - Modelado con:
     - **TensorFlow** ğŸ’¡ y **Scikit-learn** ğŸ”¬.
   - Despliegue con **Streamlit** ğŸ“º para interfaces interactivas.

6. **ğŸ“Š Visualization (VisualizaciÃ³n de Datos)**:
   - Herramienta: **Power BI** ğŸ”.
   - PropÃ³sito: Dashboards interactivos para el anÃ¡lisis y presentaciÃ³n de resultados.

7. **ğŸ”’ Version Control (Control de Versiones)**:
   - **Git** âš’ï¸ y **GitHub** ğŸ’¼: Control de versiones y colaboraciÃ³n.
   - **GitHub Actions** â³: AutomatizaciÃ³n de CI/CD.

---

### ğŸ”„ **Flujo del Pipeline**
1. **ğŸ’¡ IngestiÃ³n de Datos**:
   - Datos obtenidos de **APIs** o subida manual.
2. **ğŸ› ï¸ TransformaciÃ³n Local**:
   - EDA y limpieza con **Apache Spark** y **Python**.
3. **ğŸ’¾ Carga a la Nube**:
   - Datos subidos a **BigQuery**.
4. **ğŸ› ï¸ TransformaciÃ³n en la Nube**:
   - Procesamiento con **Cloud Dataflow** y automatizaciÃ³n con **Cloud Functions** y **Scheduler**.
5. **ğŸ“ Almacenamiento**:
   - Datos transformados almacenados en **BigQuery**.
6. **ğŸ¤– Machine Learning**:
   - Entrenamiento de modelos con **TensorFlow/Scikit-learn**.
   - VisualizaciÃ³n de resultados con **Streamlit**.
7. **ğŸ“Š VisualizaciÃ³n Final**:
   - Dashboards interactivos con **Power BI**.
8. **âš’ï¸ Control de Versiones**:
   - AutomatizaciÃ³n y control con **Git**, **GitHub** y **GitHub Actions**.

---

### ğŸ§° **TecnologÃ­as Principales**
- **BigQuery** ğŸ“‚: Almacenamiento y consulta de datos.
- **Cloud Dataflow** ğŸ› ï¸: Procesamiento escalable.
- **TensorFlow / Scikit-learn** ğŸ¤–: Modelado de datos.
- **Streamlit** ğŸ“º: Interfaces interactivas.
- **Power BI** ğŸ”: VisualizaciÃ³n de resultados.
- **Git / GitHub** ğŸ’¼: Versionado y CI/CD.
- **APIs**: Google Map Places ğŸ“, Yelp Fusion ğŸ”.


---



### ğŸš€ **Este pipeline estÃ¡ diseÃ±ado para ser escalable, automatizado y fÃ¡cil de usar**. ğŸš€



[â¬†ï¸ Volver al Ã­ndice](#Ã­ndice)

## ğŸ› ï¸ğŸ§©ğŸ’»**Stack TecnolÃ³gico**
![Imagen de WhatsApp 2024-12-16 a las 00 10 03_fe20ce49](https://github.com/user-attachments/assets/af9c2744-54a6-4e46-8c52-76dd7cdc3892)

El pipeline utiliza un **stack de herramientas escalable** y eficiente:

### âš™ï¸ **Procesamiento de Datos**:
- **Apache Spark** ğŸ› ï¸: Procesamiento distribuido.
- **Python** âœ¨: Lenguaje principal.
   - Bibliotecas: **pandas**, **numpy**, **matplotlib**.

### ğŸ“‚ **Almacenamiento en la Nube**:
- **BigQuery**: Data Warehouse.
- **Cloud Dataflow**: Procesamiento escalable.
- **Cloud Functions**: AutomatizaciÃ³n.
- **Cloud Scheduler**: ProgramaciÃ³n de tareas.

### ğŸ¤– **Machine Learning**:
- **TensorFlow / Scikit-learn**: Desarrollo y evaluaciÃ³n de modelos.
- **Streamlit**: Interfaces interactivas.

### ğŸ“Š **VisualizaciÃ³n**:
- **Power BI**: Dashboards y anÃ¡lisis.

### âš’ï¸ **Control de Versiones**:
- **Git y GitHub**: Versionado del cÃ³digo.
- **GitHub Actions**: AutomatizaciÃ³n CI/CD.

### ğŸ’¾ **IngestiÃ³n de Datos**:
- **APIs**: Google Map Places, Yelp Fusion.

---

### ğŸ¯ **Beneficios del Stack**
- âœ¨ **Escalabilidad**: Manejo eficiente de grandes volÃºmenes.
- ğŸ”„ **AutomatizaciÃ³n**: Menos procesos manuales.
- ğŸ”’ **Reproducibilidad**: Versionado con Git/GitHub.
- ğŸ“º **Interactividad**: VisualizaciÃ³n clara con Streamlit y Power BI.

---

## ğŸ“ğŸ§© MetodologÃ­a de trabajo
![metodologia](https://github.com/user-attachments/assets/4d93aefb-f479-44cf-ae86-00d417c53cdc)

Para **organizar nuestro trabajo** y **dirigir nuestros esfuerzos** hacia nuestras metas, hemos elegido trabajar con **metodologÃ­as Ã¡giles** bajo el marco de trabajo **SCRUM** ğŸš€.

Este enfoque nos permite:

- âœ… **Mejorar la organizaciÃ³n de tareas**: Asignando responsabilidades claras y manejando tiempos eficientemente.  
- ğŸ¤ **Fomentar la colaboraciÃ³n**: Promoviendo la comunicaciÃ³n constante y el trabajo en equipo.  
- ğŸ”„ **Adaptarnos rÃ¡pidamente a los cambios**: Flexibilidad ante nuevas necesidades o retos del proyecto.  
- ğŸ“¦ **Asegurar entregas continuas**: Iteraciones incrementales que mantienen el producto alineado con nuestros objetivos.\n\nTrabajar bajo **SCRUM** nos garantiza un flujo de trabajo **transparente**, **eficiente** y **enfocado en la entrega de valor**, permitiendo la mejora continua durante todo el desarrollo.

---

[â¬†ï¸ Volver al Ã­ndice](#Ã­ndice)

## â³ğŸ“…Cronograma General Gantt

![gantt](https://github.com/user-attachments/assets/e9c25815-c014-4e27-86af-31defa961134)

El cronograma general del proyecto se detalla a continuaciÃ³n, dividido en secciones como inicio, anÃ¡lisis, desarrollo y finalizaciÃ³n. Utilizamos un diagrama de Gantt para visualizar el progreso de cada tarea.

```mermaid
gantt
    title Cronograma General del Proyecto
    dateFormat  YYYY-MM-DD
    axisFormat  %d-%b

    section Sprint 1 ğŸ“
    Contextualizar la problemÃ¡tica    :done, b1, 2024-12-02, 2d
    Definiciones de objetivos y alcance  :done, a2, 2024-12-04, 1d
    Comprender los datos disponibles  :done, a2, 2024-12-04, 2d
    DefiniciÃ³n de Stack TecnolÃ³gico  :done, a2, 2024-12-05, 3d
    EDA y ETL inicial  :done, a2, 2024-12-05, 6d
    DefiniciÃ³n y KPIs  :done, a2, 2024-12-10, 1d
    PreparaciÃ³n y ensayo de presentaciÃ³n :crit, a2, 2024-12-10, 4d
    section Sprint 2 ğŸš€
    ETL completo  (16-19 Dic)    :b1, 2024-12-16, 3d
    Pipeline y automatizaciÃ³n (18-21 Dic)           :b2, 2024-12-18, 3d
    DiseÃ±o del Datawarehouse (18-22 Dic)        :b2, 2024-12-18, 5d
    DiseÃ±o del modelo ER (22 Dic)         :b2, 2024-12-22, 1d
    MVP Machine Learning  (06-09 Ene)       :b2, 2025-01-06, 3d
    DocumentaciÃ³n (06-10 Ene)       :b2, 2025-01-06, 4d
    PreparaciÃ³n y Ensayo(09-11 Ene)   :b2, 2025-01-09, 2d
    section Sprint 3 ğŸ¯
    DiseÃ±o de Reportes/Dashboards           :c1, 2025-01-13, 5d
    KPIs                  :c2, 2025-01-16, 1d
    Modelo de Machine Learning  :c2, 2025-01-13, 7d
    DocumentaciÃ³n               :d1, 2025-01-18, 5d
    PreparaciÃ³n y ensayo de presentaciÃ³n       :d2, 2025-01-22, 4d

```

**Cronograma General: Hitos y Entregables**

"El proyecto estÃ¡ diseÃ±ado para ser entregado en seis semanas, con presentaciones cada dos semanas.

**Semana 1-2:**

EDA inicial con datos de Google Maps y Yelp.
GrÃ¡ficos que muestren la informaciÃ³n limpia y general.
DefiniciÃ³n de KPIs y fÃ³rmulas, junto con las metas iniciales.

**Semana 3-4:**

ImplementaciÃ³n de un modelo predictivo para analizar la rentabilidad de las zonas priorizadas.
Mapas interactivos que representen el anÃ¡lisis geoespacial.

**Semana 5-6:**
FinalizaciÃ³n del dashboard interactivo.
PresentaciÃ³n de recomendaciones finales y conclusiones basadas en los KPIs.

**Hitos:**

Desarrollo de herramientas visuales.
DocumentaciÃ³n clara del anÃ¡lisis.
Recomendaciones estratÃ©gicas accionables."

[â¬†ï¸ Volver al Ã­ndice](#Ã­ndice)

# ğŸ”—ğŸ“‚Repositorio Github

  ğŸ“‚EDA
   
   Analisis Preliminar Google:  
      
   EDA Google: 
      
   Analisis Preliminar Yelp: 
      
   EDA Yelp:
      
  ğŸ“‚ETL
  
    ETL Google 
      
    ETL Yelp 
    
 ğŸ“‚Data
  
Google: 
 [Data Google](https://drive.google.com/drive/folders/1r-C75XM0gNzKiJPa97j-8HIiqtOzaz42)
     
Yelp: 
[Data Yelp](https://usantotomaseduco-my.sharepoint.com/personal/dianamorenoa_usantotomas_edu_co/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fdianamorenoa%5Fusantotomas%5Fedu%5Fco%2FDocuments%2FYELP%2Ddatasets&ga=1)

         
Census
      
  -- READ.ME


[â¬†ï¸ Volver al Ã­ndice](#Ã­ndice)

***
"Estamos convencidos de que este proyecto serÃ¡ el punto de partida para la expansiÃ³n exitosa de su negocio. Nuestro trabajo no solo busca identificar ubicaciones rentables, sino tambiÃ©n brindarle herramientas que faciliten decisiones basadas en datos sÃ³lidos y confiables.
Hoy le presentamos los primeros resultados de este proceso. A medida que avancemos, le mostraremos mÃ¡s hallazgos, siempre con la misiÃ³n de maximizar su Ã©xito en este sector tan competitivo."

### Contacto:
#### Claudia Jara YaÃ±ez:
Rol: Data Analyst

Github:https://github.com/claujara1975

Linkedin: https://www.linkedin.com/in/claudia-jara-1517361a5/

#### Saray Pacheco Ramos:
Rol: Data Analyst  

Github: https://github.com/ssaraypr

#### Sergio Castro: Limpieza y anÃ¡lisis del dataset Google.
Rol: Data Engineer

Github:https://github.com/SDCaFlo

LinkedIn: 
#### Diana Moreno: Limpieza y anÃ¡lisis del dataset Yelp.
Rol:  Data Engineer

Github: https://github.com/dianitafeliz

LinkedIn:
#### Felipe Dedes : Machine learning y despliegue.
Rol: Machine Learning Engineer

Github:https://github.com/DedesF

LinkedIn:
#### Greta Combold: Machine Learning y despliegue.
Rol: Machine Learning Engineer

Github: https://github.com/PerlaMarGreta

LinkedIn:

[â¬†ï¸ Volver al Ã­ndice](#Ã­ndice)
### Sprint 2 
![S2 ent](https://github.com/user-attachments/assets/52f02cc6-e0f2-46a8-9abb-ee04b9a36671)

## ğŸ“šÃndice del SPRINT 2
# Proyecto: ğŸŒŸ PredicciÃ³n de Crecimiento EconÃ³mico para Negocios de â˜• Coffee & ğŸ¥ Brunch

## ğŸ“š Ãndice
| ğŸ—‚ï¸ SecciÃ³n                                | ğŸ”— Enlace                                     |
|-----------------------------------------|---------------------------------------------|
| **ğŸ› ï¸ Elementos del ETL**                | [ETL completo](#etl-completo)               |
|                                         | [ğŸ“Š Estructura de datos implementada](#estructura-de-datos-implementada) |
|                                         | [ğŸš€ Pipeline ETL automatizado](#pipeline-etl-automatizado) |
|                                         | [ğŸ“ DiseÃ±o del Modelo ER](#diseÃ±o-del-modelo-er) |
|                                         | [ğŸ”„ Pipelines para alimentar el DW](#pipelines-para-alimentar-el-dw) |
|                                         | [ğŸ¢ Data Warehouse](#data-warehouse)         |
|                                         | [ğŸ¤– AutomatizaciÃ³n](#automatizaciÃ³n)         |
|                                         | [âœ”ï¸ ValidaciÃ³n de datos](#validaciÃ³n-de-datos) |
|                                         | [ğŸ“œ DocumentaciÃ³n](#documentaciÃ³n)           |
|                                         | [ğŸ“ˆ Diagrama ER detallado](#diagrama-er-detallado) |
|                                         | [ğŸ“š Diccionario de datos](#diccionario-de-datos) |
|                                         | [ğŸ”§ Workflow detallando tecnologÃ­as](#workflow-detallando-tecnologÃ­as) |
|                                         | [ğŸ” AnÃ¡lisis de datos de muestra](#anÃ¡lisis-de-datos-de-muestra) |
| **ğŸ“… Ciclo de vida del dato**           | [ğŸ”„ Ciclo de vida del dato](#ciclo-de-vida-del-dato) |
| **ğŸ’¡ Prototipos y Productos**           |                                             |
|                                         | [ğŸ¤– MVP/ Proof of Concept de producto de ML](#mvp-proof-of-concept-de-producto-de-ml) |
|                                         | [ğŸ“Š MVP/ Proof of Concept de Dashboard](#mvp-proof-of-concept-de-dashboard) |


---

AsÃ­, el **ciclo de vida del dato** se encuentra antes de los productos y prototipos, proporcionando una visiÃ³n clara sobre cÃ³mo se gestionan y procesan los datos antes de ser utilizados en la creaciÃ³n de modelos y dashboards.
## ğŸ” **ğŸ› ï¸ Elementos del ETL**

### ğŸŒ ETL completo
El proceso de **ETL** incluye:
- ğŸ“¥ **ExtracciÃ³n** de datos desde fuentes como ğŸ—ºï¸ Yelp, ğŸ—ºï¸ Google Maps y Census.
- ğŸ”„ **TransformaciÃ³n** y limpieza de datos para garantizar calidad y uniformidad.
- ğŸš€ **Carga** en un **ğŸ“Š Data Warehouse** centralizado en BigQuery.

### ğŸ“Š Estructura de datos implementada
La estructura sigue un modelo optimizado para consultas analÃ­ticas:
- ğŸ—‚ï¸ Tablas principales: Negocios, reseÃ±as, ventas, usuarios y datos demogrÃ¡ficos.
- ğŸ“ˆ Cada tabla estÃ¡ diseÃ±ada para consultas rÃ¡pidas y modelado predictivo.

### ğŸš€ Pipeline ETL automatizado
El pipeline incluye:
- ğŸ¤– AutomatizaciÃ³n para extracciÃ³n, transformaciÃ³n y carga.
- âœ”ï¸ ValidaciÃ³n de datos para garantizar integridad y consistencia.
- ğŸ•’ EjecuciÃ³n programada semanalmente para mantener actualizados los datos.

### ğŸ“ DiseÃ±o del Modelo ER
El modelo incluye:
- ğŸ”— Relaciones entre negocios, usuarios y ventas, destacando interacciones clave.
- ğŸ—ºï¸ Tablas auxiliares para datos geogrÃ¡ficos y demogrÃ¡ficos.
- Claro, aquÃ­ tienes los textos bien estructurados con emojis para que puedas agregarlos a tu GitHub:

El **diseÃ±o del modelo ER** para el sistema de anÃ¡lisis de datos de negocios incluye una estructura conceptual y global de las entidades y sus relaciones. A continuaciÃ³n, se destacan los elementos clave:

- ğŸ¢ **Entidad central: `business`**  
  Representa los negocios registrados, con informaciÃ³n relevante como nombre, direcciÃ³n, ciudad, estado, coordenadas, categorÃ­as y atributos especÃ­ficos del negocio. Esta entidad estÃ¡ relacionada con varias otras entidades secundarias.

- ğŸ”— **Entidades relacionadas:**
  - ğŸ“ `reviews`: Almacena reseÃ±as realizadas por usuarios, asociadas a negocios y usuarios, con detalles como texto, calificaciÃ³n y utilidad.
  - ğŸ‘¤ `user`: Representa a los usuarios del sistema, incluyendo atributos como nombre, nÃºmero de reseÃ±as y promedio de estrellas.
  - ğŸ“… `checkin`: Registra las visitas a los negocios en fechas especÃ­ficas.
  - ğŸ’¬ `tip`: Contiene consejos o comentarios breves hechos por los usuarios, vinculados a los negocios.
  - ğŸ’µ `sales`: Registra informaciÃ³n sobre ventas por trimestre y aÃ±o, asociada con los negocios.
  - ğŸŒ `google_misc`: InformaciÃ³n complementaria de Google vinculada a cada negocio.
  - ğŸŒ `population_per_state`: Proporciona datos demogrÃ¡ficos por estado y aÃ±o, Ãºtil para anÃ¡lisis en modelos de **machine learning**.

El modelo **ER** es de tipo **copo de nieve**, lo que significa que las entidades estÃ¡n **normalizadas** en tablas pequeÃ±as y especÃ­ficas, lo que ayuda a reducir redundancias y optimizar el anÃ¡lisis.

Este diseÃ±o conceptual establece las bases para la estructura de la base de datos y organiza la informaciÃ³n de forma clara y eficiente, optimizando la velocidad y precisiÃ³n del anÃ¡lisis.

---

### ğŸ”„ Pipelines para alimentar el DW
Los pipelines automatizados alimentan el **ğŸ“Š Data Warehouse** con:
- ğŸ“… Datos actualizados de Yelp, Google Maps y Census.
- ğŸ†• Nuevas reseÃ±as y ventas trimestrales, asegurando datos recientes.

### ğŸ¢ Data Warehouse
El **Data Warehouse** centraliza y organiza datos para anÃ¡lisis y modelos predictivos:
- âš¡ Optimizado para consultas analÃ­ticas y reportes.
- ğŸ“ˆ ConfiguraciÃ³n escalable para soportar crecimiento de datos.

### ğŸ¤– AutomatizaciÃ³n
Todo el proceso es automatizado con:
- ğŸ•’ Workflows programados que ejecutan tareas crÃ­ticas.
- â˜ï¸ Cloud Functions y herramientas de GCP para orquestar operaciones.
Link del video para ver el proceso:
[Link del video](https://drive.google.com/file/d/1keAXoYo-qoZnxgP-6pQOmW9OrGWwkflr/view?usp=sharing)


### âœ”ï¸ ValidaciÃ³n de datos
El pipeline incluye pasos de validaciÃ³n para:
- ğŸ—‘ï¸ Eliminar duplicados y detectar inconsistencias.
- ğŸ“Š Garantizar que los datos cumplen estÃ¡ndares de calidad esperados.

### ğŸ“œ DocumentaciÃ³n
La documentaciÃ³n incluye:
- ğŸ“‹ Detalles tÃ©cnicos del proceso ETL y su implementaciÃ³n.
- ğŸ› ï¸ Instrucciones claras para ejecuciÃ³n y mantenimiento.
- ğŸ–Šï¸ Manuales para incorporar nuevas fuentes de datos.

### ğŸ“ˆ Diagrama ER detallado
El diagrama **ER** detalla:
- ğŸ—‚ï¸ Tablas principales, auxiliares y sus relaciones.
- ğŸ”‘ Claves primarias y forÃ¡neas, destacando conexiones de datos.

El **diagrama ER detallado** es la representaciÃ³n visual precisa y tÃ©cnica del diseÃ±o de la base de datos. En este diagrama se muestra:

- ğŸ”  **Entidades**: Las tablas principales y sus atributos especÃ­ficos.
- ğŸ”— **Relaciones**: Las conexiones entre las entidades, indicando cÃ³mo se vinculan y la cardinalidad de las relaciones.
- ğŸ”‘ **Llaves primarias (PK) y forÃ¡neas (FK)**: Se especifican las claves que identifican de manera Ãºnica cada registro y las relaciones entre las tablas.
- âš–ï¸ **Restricciones y tipos de datos**: InformaciÃ³n detallada sobre las restricciones aplicadas a los campos (por ejemplo, campos no nulos) y los tipos de datos asociados a cada atributo.

A continuaciÃ³n, se presenta un **diagrama ER detallado** de la estructura de la base de datos, donde se incluyen las **tablas** y sus **relaciones**:

![Diagrama ER](ruta/a/tu/imagen.png)  
*(Imagen representando la estructura detallada de las tablas y sus relaciones)*

Este diagrama ofrece una visiÃ³n completa y tÃ©cnica de la estructura, permitiendo una implementaciÃ³n precisa de la base de datos en el sistema. Los detalles como **tipos de datos**, **llaves primarias y forÃ¡neas**, y las relaciones entre las entidades son fundamentales para garantizar la integridad y el rendimiento del sistema.

---

En resumen:
- El **DiseÃ±o del Modelo ER** proporciona una visiÃ³n **conceptual** del sistema, estructurando las entidades y sus relaciones de manera global.
- El **Diagrama ER Detallado** se enfoca en los aspectos **tÃ©cnicos**, presentando la estructura precisa de las tablas, relaciones y claves.

La **imagen con las tablas y sus relaciones** debe ir en la secciÃ³n del **Diagrama ER Detallado**, donde se visualizan todos los detalles tÃ©cnicos.


## ğŸ“š Diccionario de datos
![diccionario de datos](https://github.com/user-attachments/assets/b2f3002f-061b-401b-b2b7-7e00a3b19a3b)

El diccionario describe:
- ğŸ·ï¸ Estructura de las tablas: nombres, tipos de datos y relaciones.
- ğŸ–Šï¸ DefiniciÃ³n clara de cada campo y su propÃ³sito dentro del modelo.
- AquÃ­ tienes el texto estructurado y con emojis para agregarlo a tu GitHub:

---

## ğŸ“š Diccionario de Datos

En este repositorio podrÃ¡n encontrar un **diccionario de datos** que ofrece una descripciÃ³n detallada y precisa de cada uno de los elementos que conforman el modelo. Este documento incluye informaciÃ³n clave como:

- ğŸ›ï¸ **Entidades y tablas**: Las tablas que estructuran los datos.
- ğŸ§© **Atributos de cada entidad**: Detalles especÃ­ficos de cada campo o columna dentro de las tablas.
- ğŸ”¢ **Tipos de datos**: Los tipos de datos asociados a cada campo.
- ğŸ”‘ **Llaves primarias (PK)**: Identificadores Ãºnicos para cada registro.
- ğŸ”— **Llaves forÃ¡neas (FK)**: Definen las relaciones entre las tablas.
- âš–ï¸ **Restricciones o reglas aplicadas**: Reglas que garantizan la integridad de los datos.

La imagen que presentamos corresponde a una secciÃ³n del **diccionario de datos** y muestra la estructura de una de las tablas de la base de datos. En ella podemos observar:

- ğŸ“ Los **atributos** que forman parte de la tabla.
- ğŸ”  Los **tipos de datos** asociados a cada campo.
- ğŸ“‹ La **descripciÃ³n detallada** de cada atributo.
- ğŸ”‘ La **clave primaria**, que permite identificar de manera Ãºnica a cada registro.


### ğŸ”§ Workflow detallando tecnologÃ­as
El workflow utiliza:
- ğŸ“Š **BigQuery** para almacenamiento y anÃ¡lisis de grandes volÃºmenes.
- â˜ï¸ **Cloud Functions** para integraciÃ³n y tareas automatizadas.
- ğŸ”— APIs externas como Yelp y Census para extracciÃ³n de datos crÃ­ticos.

### ğŸ” AnÃ¡lisis de datos de muestra
El anÃ¡lisis de muestra incluye:
- ğŸ” ExploraciÃ³n de datos histÃ³ricos para identificar tendencias relevantes.
- ğŸ“Š SegmentaciÃ³n de negocios por ubicaciÃ³n, reseÃ±as y ventas.

---

## ğŸš€ **ğŸ’¡ Prototipos y Productos**
![MVPML](https://github.com/user-attachments/assets/2db39555-2eee-49f1-9eba-bdeafe7336b8)

## ğŸ¤– MVP/ Proof of Concept de producto de ML
Modelo inicial para predecir crecimiento basado en:
- ğŸ’° Ventas, â­ reseÃ±as y ğŸ“ ubicaciÃ³n.
- ğŸ§  Algoritmos supervisados como ğŸŒ² Random Forest y ğŸ“ˆ XGBoost.
- ğŸ“Š Variables clave: promedio de reseÃ±as, densidad de negocios y datos demogrÃ¡ficos.
AquÃ­ tienes un resumen estructurado para la secciÃ³n MVP de ML de tu README en GitHub, con algunos emojis para hacerlo mÃ¡s visual y amigable:

---

## ğŸš€ MVP de Machine Learning

En este proyecto, hemos desarrollado un modelo de **Machine Learning** para predecir el **crecimiento econÃ³mico de negocios de cafÃ©** utilizando datos clave como:

- ğŸ“Š **ReseÃ±as de clientes**
- ğŸ’° **Ventas mensuales**
- ğŸ“ **UbicaciÃ³n de los negocios**

### ğŸ” Modelo de PredicciÃ³n

El modelo se entrena con **datos histÃ³ricos de ventas** y **valoraciones** para estimar el **porcentaje de crecimiento de las ventas** en los prÃ³ximos meses. Utilizamos un **RandomForestRegressor** para identificar patrones entre las caracterÃ­sticas de cada negocio y su desempeÃ±o.

### ğŸŒŸ Interfaz Interactiva

Creamos una **interfaz interactiva** con **Streamlit** que permite a los usuarios:

- ğŸ—ºï¸ **Explorar negocios de cafÃ©** mediante un **mapa interactivo** filtrado por ubicaciÃ³n, reseÃ±as, ventas y otras variables.
- ğŸ” **Visualizar predicciones de crecimiento** con filtros personalizables.
- ğŸ¢ **Ingresar direcciones** y obtener una lista de negocios cercanos con su predicciÃ³n de crecimiento.

### âš¡ OptimizaciÃ³n y Resultados

- ğŸƒâ€â™‚ï¸ **OptimizaciÃ³n del proceso** con **BigQuery** para ofrecer resultados rÃ¡pidos y precisos.
- ğŸ“ˆ **Modelo entrenado previamente**, lo que garantiza la eficiencia en las predicciones.
- ğŸ“Š **DiseÃ±o intuitivo** que facilita la interpretaciÃ³n de los datos y toma de decisiones informadas.

---

Este formato destaca los puntos clave de forma clara y visual, usando emojis para hacerlo mÃ¡s atractivo.
### ğŸ“Š MVP/ Proof of Concept de Dashboard
![MVPDASH](https://github.com/user-attachments/assets/80fdab82-9687-406c-b948-031f44fb841f)

Dashboard interactivo para visualizar:
- ğŸ“ˆ Predicciones del modelo con grÃ¡ficos claros e intuitivos.
- ğŸ” Datos clave: ventas, puntuaciones y tendencias trimestrales.
- ğŸ›ï¸ Filtros por ubicaciÃ³n, perÃ­odo y caracterÃ­sticas especÃ­ficas.

**ğŸ” Insights accionables con nuestro Dashboard interactivo:**

1ï¸âƒ£ **Secciones TemÃ¡ticas**: El dashboard estÃ¡ dividido en Ã¡reas especÃ­ficas para visualizar datos clave.  
2ï¸âƒ£ **ğŸ“Š KPIs y Tendencias**: Paneles con KPIs (âœ… verde = cumplido, âŒ rojo = no cumplido) y anÃ¡lisis de tendencias. Ejemplo: **Incremento en Ventas (+4%)**.  
3ï¸âƒ£ **ğŸ›ï¸ Filtros**: Aplica filtros por ğŸ—“ï¸ aÃ±os o ğŸ“ ubicaciones para explorar:  
   - Cantidad de negocios.  
   - Ciudades con mÃ¡s negocios.  

**ğŸ” AnÃ¡lisis TemÃ¡tico:**

- **ğŸ’¬ ReseÃ±as**: Tendencia trimestral de reseÃ±as, ranking de ciudades con mÃ¡s reseÃ±as ğŸŒŸ, y un mapa de distribuciÃ³n geogrÃ¡fica.  
- **â­ Puntajes**: EvoluciÃ³n del puntaje promedio por ciudad ğŸ“, identificando Ã¡reas con mÃ¡s interacciones.  
- **ğŸ“ Ubicaciones**: Mapa interactivo de â­ estrellas por negocios, con filtros para observar zonas con menos o mÃ¡s calificaciones.  

**ğŸ“ˆ AnÃ¡lisis Avanzado:**
Ejemplo:  
- Chicago: â­ 4.3 promedio, 492 negocios.  
- New York: â­ 4.16 promedio, 1,810 negocios.  
Esto muestra que cantidad â‰  calidad, indicando posibles factores como servicio superior en Chicago.

**âš™ï¸ Funcionalidad:**  
Conectado a **BigQuery** para consultas actualizadas e interactivas en tiempo real. ğŸ¯

âœ¨ Este dashboard es una herramienta poderosa para decisiones estratÃ©gicas, optimizando el crecimiento de negocios Coffee & Brunch. â˜•ğŸ¥
---



### Sprint 3
![S3 ent](https://github.com/user-attachments/assets/f0cf9987-0614-4451-97a3-158565f614e1)

## ğŸ“šÃndice del Proyecto

##### ğŸ“šÃndice del Sprint 3
| **SecciÃ³n**                        | **Enlace**                            |
|-----------------------------------|---------------------------------------|
| **Hitos**                         |                                       |
|                                   | [DiseÃ±o de Reportes/Dashboards](#diseÃ±o-de-reportesdashboards) |
|                                   | [KPIs](#kpis)                        |
|                                   | [Modelos de ML](#modelos-de-ml)       |
|                                   | [Modelo de ML en ProducciÃ³n](#modelo-de-ml-en-producciÃ³n) |
|                                   | [DocumentaciÃ³n](#documentaciÃ³n)       |
|                                   | [SelecciÃ³n del Modelo y Feature Engineering](#selecciÃ³n-del-modelo-y-feature-engineering) |
|                                   | [Informe de AnÃ¡lisis](#informe-de-anÃ¡lisis) |
| **RÃºbrica**                       |                                       |
|                                   | [Objetivos Tech](#objetivos-tech)     |
|                                   | [DiseÃ±o del Dashboard](#diseÃ±o-del-dashboard) |
|                                   | [Funcionalidad y Usabilidad](#funcionalidad-y-usabilidad) |
|                                   | [KPIs (RÃºbrica)](#kpis-rubrica)       |
|                                   | [EDA / Feature Selection](#eda--feature-selection) |
|                                   | [Modelo Machine Learning](#modelo-machine-learning) |
|                                   | [Modelo ML en ProducciÃ³n (RÃºbrica)](#modelo-ml-en-producciÃ³n-rubrica) |

---

# Hitos

## DiseÃ±o de Reportes/Dashboards
![1](https://github.com/user-attachments/assets/44620292-609f-4ea5-8a10-993c086d112d)

El dashboard interactivo diseÃ±ado tiene un Panel de NavegaciÃ³n intuitivo y se organiza en diferentes pestaÃ±as, cada una con un enfoque especÃ­fico.
Las pestaÃ±as incluyen ReseÃ±as, Valoraciones, Ventas, Ubicaciones, Puntajes, y Conclusiones. Cada pestaÃ±a estÃ¡ enfocada en proporcionar informaciÃ³n relevante para la expansiÃ³n del negocio, con visualizaciones y KPIs.
Estructura y estÃ©tica: El diseÃ±o incluye filtros y grÃ¡ficos interactivos (como el de ventas y puntajes) que facilitan el anÃ¡lisis.

## KPIs
![2](https://github.com/user-attachments/assets/b65da720-522e-4a78-9613-66433bd88944)

Los KPIs definidos son:
Crecimiento de la puntuaciÃ³n promedio (meta 2%)
Crecimiento de las ventas (meta 4%)
Crecimiento en la cantidad de reseÃ±as (meta 2%)
Crecimiento de los comentarios positivos (meta 2%)
Cada KPI se visualiza en el dashboard para permitir un anÃ¡lisis fÃ¡cil y rÃ¡pido.

## DocumentaciÃ³n
![5](https://github.com/user-attachments/assets/7e02c074-f3bf-467a-9609-d556822683f1)

Se ha documentado todo el proceso: desde la limpieza de datos y recolecciÃ³n hasta el desarrollo de modelos y el diseÃ±o del dashboard.
AdemÃ¡s, la presentaciÃ³n final incluye los hallazgos clave y el anÃ¡lisis detallado de los KPIs.


## SelecciÃ³n del Modelo y Feature Engineering
![6](https://github.com/user-attachments/assets/c006c331-8fc3-4ce5-addf-6c31a1503a0c)

Detalla el proceso de selecciÃ³n del modelo y las tÃ©cnicas de feature engineering utilizadas.

## Informe de AnÃ¡lisis
![7](https://github.com/user-attachments/assets/e219ff7d-45db-44a5-a7d1-8c7158a40854)

El anÃ¡lisis de los datos de reseÃ±as, valoraciones y ventas se presenta a travÃ©s de grÃ¡ficos interactivos que muestran tendencias y patrones, lo que facilita la interpretaciÃ³n para tomar decisiones estratÃ©gicas
# RÃºbrica

## Objetivos Tech
![8](https://github.com/user-attachments/assets/b4a7cc93-fcc7-43ab-b08c-96ce85b4a28e)


Documenta los objetivos tecnolÃ³gicos del proyecto.

## DiseÃ±o del Dashboard
![9](https://github.com/user-attachments/assets/8dc859b2-c46c-4047-95aa-fc40fc70f1d4)

El anÃ¡lisis de los datos de reseÃ±as, valoraciones y ventas se presenta a travÃ©s de grÃ¡ficos interactivos que muestran tendencias y patrones, lo que facilita la interpretaciÃ³n para tomar decisiones estratÃ©gicas

## Funcionalidad y Usabilidad
![10](https://github.com/user-attachments/assets/8cd7d84d-aee6-478b-9a98-d7ea77185f7f)

El dashboard es completamente interactivo, lo que garantiza una funcionalidad y usabilidad Ã³ptimas para los usuarios.
Las visualizaciones son claras, y los usuarios pueden filtrar y explorar los datos fÃ¡cilmente.

## KPIs (RÃºbrica)
![2](https://github.com/user-attachments/assets/4e6b9a8e-10ea-45b8-ae0e-4fb1cf61a735)

Describe los KPIs evaluados para la rÃºbrica.

## EDA / Feature Selection
![11](https://github.com/user-attachments/assets/7cad574e-92ef-4be5-9d8d-4ed91eff4577)

Explica cÃ³mo realizaste el anÃ¡lisis exploratorio de datos y la selecciÃ³n de caracterÃ­sticas.

## Modelo Machine Learning
![12](https://github.com/user-attachments/assets/7953670a-e3e5-4124-acc8-10c23c7af850)
Se han desarrollado dos modelos de machine learning:
AnÃ¡lisis de Sentimientos: Para medir el nivel de satisfacciÃ³n del consumidor a partir de los comentarios de los clientes.
Prediccion de Exito: Para predecir el potencial econÃ³mico de nuevas ubicaciones.
Ambos modelos estÃ¡n diseÃ±ados para facilitar la toma de decisiones estratÃ©gicas basadas en datos.
Los modelos de ML se enfocan en el anÃ¡lisis de sentimientos y la estimaciÃ³n del impacto econÃ³mico de las ubicaciones. Estos estÃ¡n en producciÃ³n y operativos en la nube.
Explicacion del Modelo de Analisis de sentimientos:

# **Modelo de Sentimientos** ğŸ§ ğŸ’¬

Para el anÃ¡lisis de sentimientos de las **reseÃ±as de los clientes**, utilizamos tÃ©cnicas de procesamiento de lenguaje natural (**NLP**) y un modelo preentrenado llamado **RoBERTa** ğŸš€. Este modelo es una variante optimizada de **BERT** y fue utilizado para clasificar las reseÃ±as en tres categorÃ­as: 

- **Negativo** âŒ
- **Neutro** ğŸ˜
- **Positivo** âœ…

## **Procedimiento Inicial** ğŸ
En un primer intento, aplicamos el modelo preentrenado estÃ¡ndar proporcionado por la librerÃ­a, utilizando una porciÃ³n de los datos. Sin embargo, descubrimos que el modelo no clasificaba correctamente las reseÃ±as para nuestra tarea especÃ­fica.

ğŸ“‰ **Ejemplo:** Un comentario que mencionaba:  
> "La atenciÃ³n es buena, la comida mejor, pero el aseo deja mucho que desear, por lo que no volverÃ­a".  
Este comentario fue clasificado errÃ³neamente como **Neutro** o **Positivo**. Para nosotros, este deberÃ­a haber sido **Negativo**. ğŸ˜•

## **Entrenamiento Personalizado** ğŸ”§
Para mejorar el modelo, decidimos **entrenarlo con un conjunto de datos clasificados manualmente** por cada uno de los miembros del equipo. Definimos mÃ¡s detalladamente quÃ© comentarios se consideraban **positivos**, **neutros** o **negativos**. 

Tras este ajuste, el modelo mostrÃ³ **mejoras significativas** en la clasificaciÃ³n, corrigiendo los errores anteriores. ğŸ“ˆ

## **Resultados Iniciales** ğŸ”
En la **evaluaciÃ³n inicial**, el modelo mostrÃ³ una **exactitud del 58%**, con una tendencia a sobrestimar los comentarios como **positivos**. Este resultado no fue adecuado para nuestra aplicaciÃ³n.

## **Mejoras Post-Entrenamiento** ğŸ“Š
DespuÃ©s de realizar el entrenamiento personalizado, el modelo fue reejecutado y evaluado nuevamente, logrando **mejorar considerablemente la precisiÃ³n** y **corrigiendo la sobreestimaciÃ³n** de los comentarios positivos.

## **Detalles TÃ©cnicos** ğŸ”¬

**RoBERTa** es un modelo **descendiente de BERT** optimizado y preentrenado con una mayor cantidad de datos. 

âœ… **CaracterÃ­sticas destacadas de RoBERTa:**
- **TokenizaciÃ³n dinÃ¡mica** para un manejo mÃ¡s eficiente de las secuencias.
- Capacidad de manejar **textos mÃ¡s largos** con mayor eficiencia.

### **MÃ©tricas utilizadas** âš™ï¸:
- **PrecisiÃ³n (Precision)**: Mide la proporciÃ³n de predicciones correctas para una clase entre todas las predicciones realizadas para esa clase.
- **Recall**: Mide la proporciÃ³n de instancias de una clase correctamente identificadas por el modelo.
- **F1 Score**: Es la **media armÃ³nica** entre la precisiÃ³n y el recall, proporcionando un balance entre ambos.

---

Este modelo nos permitiÃ³ mejorar significativamente la clasificaciÃ³n de los **sentimientos** en las reseÃ±as y ajustarlo especÃ­ficamente a las necesidades de nuestro negocio. ğŸ’¡ğŸ“ˆ

## Modelo ML en ProducciÃ³n 
![4](https://github.com/user-attachments/assets/fdcd7ec0-1a85-42e0-bc12-b2fc0b7908ec)
# ImplementaciÃ³n del Modelo de PredicciÃ³n de Crecimiento EconÃ³mico de Negocios de CafÃ©

Este modelo de **Machine Learning** se centra en predecir el **porcentaje de crecimiento econÃ³mico** de los negocios, como las cafeterÃ­as, en base a diversos factores, tales como las **valoraciones de los clientes**, el **sentimiento en las reseÃ±as**, las **ventas mensuales**, y las **coordenadas geogrÃ¡ficas** de cada negocio. La implementaciÃ³n de este modelo sigue un proceso detallado y estructurado que garantiza su efectividad y precisiÃ³n en la predicciÃ³n del crecimiento.

## 1. ObtenciÃ³n de Datos (BigQuery) ğŸ“Š

El primer paso del proceso es la **extracciÃ³n de datos relevantes** desde **BigQuery**, donde se almacenan diversas tablas relacionadas con los negocios de cafÃ©, las reseÃ±as de clientes, las ventas mensuales y los puntajes de sentimiento. La consulta selecciona datos clave, tales como:

- **Promedio de estrellas** en las reseÃ±as (puntuaciones de los clientes) â­
- **Puntajes de sentimiento** (positivo, neutro, negativo) derivados de las reseÃ±as ğŸ’¬
- **Ventas mensuales** de los negocios ğŸ’°
- **Coordenadas geogrÃ¡ficas** de cada negocio (latitud y longitud) ğŸ“

## 2. CÃ¡lculo del Crecimiento ğŸ“ˆ

Con los datos obtenidos, el siguiente paso es calcular el **porcentaje de crecimiento** en las ventas de cada negocio mes a mes. Esto se realiza comparando las ventas actuales con las ventas del mes anterior, utilizando la fÃ³rmula del cÃ¡lculo de crecimiento porcentual:

\[
\text{Crecimiento porcentual} = \frac{\text{Ventas actuales} - \text{Ventas mes anterior}}{\text{Ventas mes anterior}} \times 100
\]

## 3. Entrenamiento del Modelo ğŸ¤–

Para predecir el porcentaje de crecimiento econÃ³mico, el modelo se entrena utilizando el **algoritmo de Random Forest Regressor**. Este algoritmo es adecuado para abordar problemas de regresiÃ³n y permite hacer predicciones sobre variables continuas, como el porcentaje de crecimiento de ventas. Las caracterÃ­sticas utilizadas para entrenar el modelo son:

- **StarsReviews**: Promedio de estrellas de las reseÃ±as ğŸŒŸ
- **SentimientoScore**: Puntaje de sentimiento derivado de las reseÃ±as ğŸ˜ŠğŸ˜ğŸ˜
- **latitude y longitude**: UbicaciÃ³n geogrÃ¡fica del negocio ğŸ“
- **monthly_sales**: Ventas mensuales del negocio ğŸ’¸

El conjunto de datos se divide en un **80%** para entrenamiento y un **20%** para prueba, lo que permite evaluar el desempeÃ±o del modelo utilizando mÃ©tricas como el **RMSE** (Root Mean Squared Error) y el **RÂ²** (Coeficiente de determinaciÃ³n), indicadores clave de cuÃ¡n bien se ajusta el modelo a los datos reales.

## 4. Ajuste de HiperparÃ¡metros con GridSearchCV âš™ï¸

Para optimizar la precisiÃ³n del modelo, se utiliza **GridSearchCV** para realizar una bÃºsqueda exhaustiva de los mejores **hiperparÃ¡metros** del **RandomForestRegressor**. Este proceso permite encontrar la combinaciÃ³n ideal de parÃ¡metros, como el nÃºmero de Ã¡rboles (**n_estimators**) y la profundidad mÃ¡xima de los Ã¡rboles (**max_depth**), entre otros. El ajuste de estos parÃ¡metros mejora significativamente el rendimiento del modelo y, por lo tanto, la exactitud de las predicciones.

## 5. Guardado y Carga del Modelo ğŸ’¾

Una vez entrenado, el modelo se guarda en un archivo `.pkl` utilizando la librerÃ­a `joblib`. Esto facilita su carga en el futuro sin necesidad de reentrenar el modelo desde cero. En caso de que el modelo ya exista, se carga directamente desde el archivo para realizar las predicciones sin pÃ©rdida de tiempo.

## 6. PredicciÃ³n de Crecimiento ğŸš€

Al realizar una predicciÃ³n, se ingresan datos relevantes, como:

- **StarsReviews** (Ej. 4.5 estrellas) ğŸŒŸ
- **SentimientoScore** (Ej. 1, lo que representa un sentimiento positivo) ğŸ˜Š
- **Latitud y longitud** del negocio ğŸ“
- **Ventas mensuales** del negocio ğŸ’¸

Con estos datos, el modelo predice el **porcentaje de crecimiento** para el prÃ³ximo trimestre. Posteriormente, se calcula la **ganancia esperada** aplicando el porcentaje de crecimiento al valor actual de las ventas, ofreciendo asÃ­ una proyecciÃ³n del desempeÃ±o econÃ³mico a futuro.

## 7. Flujo de Trabajo ğŸ”„

El flujo de trabajo del modelo sigue un proceso claro:

- Si el modelo **no existe**, se entrena desde cero.
- Si el modelo **ya existe**, se carga y se utiliza para hacer predicciones.
- Los resultados proporcionan informaciÃ³n valiosa que permite tomar **decisiones estratÃ©gicas** en torno a la expansiÃ³n o mejora de los negocios.

## 8. ProducciÃ³n del Modelo ğŸŒ

Este modelo estÃ¡ diseÃ±ado para ser desplegado en un entorno de **producciÃ³n en la nube**, facilitando su acceso mediante una **interfaz grÃ¡fica interactiva** conectada a un **dashboard**. Esto permite que los responsables de tomar decisiones en el negocio puedan visualizar las predicciones en **tiempo real** y utilizar los resultados para planificar estrategias de expansiÃ³n o ajuste.

## Aplicaciones para Negocios como Corner Bakery CafÃ© ğŸ¥

El enfoque del modelo en la **predicciÃ³n de crecimiento econÃ³mico** es particularmente Ãºtil para negocios como **Corner Bakery CafÃ©**. Con los resultados proporcionados por el modelo, es posible **identificar Ã¡reas con alto potencial de crecimiento** y planificar la **expansiÃ³n** en mercados con mayor demanda, basÃ¡ndose en datos histÃ³ricos y predicciones precisas.

Este modelo no solo optimiza la toma de decisiones estratÃ©gicas, sino que tambiÃ©n ayuda a maximizar las oportunidades de **expansiÃ³n** y mejora continua, lo que resulta en un enfoque mÃ¡s eficiente y rentable para los negocios de cafÃ© en expansiÃ³n.


