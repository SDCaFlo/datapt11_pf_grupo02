### <p align="center">  ‚òïProyecto: </p>
# <p align="center"> üìä An√°lisis de Inversi√≥n </p>
## <p align="center"> ü•ê Coffee & Brunch Bussiness </p>

## üìö√çndice
 
| Secci√≥n                         | Enlace                           |
|--------------------------------|----------------------------------|
| **Items que tiene que tener la propuesta**          | [Equipo de trabajo](#equipo-de-trabajo) |
|                                | [Entendimiento de la situaci√≥n actual](#entendimiento-de-la-situaci√≥n-actual) |
|                                | [Objetivos](#objetivos)          |
|                                | [Alcance](#alcance)              |
|                   | [KPIs](#kpis)                    |
|          | [Repositorio Github](#repositorio-github) |
| **Hitos**                      |                                  |
|                         | [3KPIs](#kpis)                   |
| | [Alcance](#alcance)              |
|              | [EDA de los datos](#stack-tecnol√≥gico) |
|             | [Repositorio Github](#repositorio-github) |
|             | [Stack Tecnol√≥gico](#stack-tecnol√≥gico) |
|          | [Metodolog√≠a de trabajo](#metodolog√≠a-de-trabajo) |
|                | [Dise√±o detallado](#dise√±o-detallado) |
|        | [Cronograma general Gantt](#cronograma-general-gantt) |
| | [An√°lisis preliminar de calidad de datos](#an√°lisis-preliminar-de-calidad-de-datos) |
| **Documentaci√≥n:**                      |                                  |
|                                |     [Stack elegido y fundamentaci√≥n](#Cronograma-general-Gantt)|
|                                |    [Flujo de trabajo](#Flujo-de-trabajo)|
 
---



# Equipo de Trabajo:

Presentaci√≥n de Nuestro Equipo de Ciencia de Datos
| üìä **Analistas de Datos** | üõ†Ô∏è **Ingenieros de Datos** | ü§ñ **Ingenieros de Machine Learning** |
|---------------------------|---------------------------|--------------------------------------|
| ![Claudia y Saray](https://github.com/user-attachments/assets/e24182ce-f116-407d-85f6-e28b149b2f52) | ![Diana y Sergio](https://github.com/user-attachments/assets/c779c3d7-47bb-4c0a-9942-5d8d327701ee) | ![Felipe y Greta](https://github.com/user-attachments/assets/e56af139-909e-48d6-be6b-0313307f840b) |
| **Claudia Jara y Saray Pacheco** <br> Expertas en explorar, interpretar y visualizar los datos, Claudia y Saray son clave para descubrir patrones, generar insights estrat√©gicos y presentar informaci√≥n clara que facilita la toma de decisiones. | **Diana Moreno y Sergio Castro** <br> Diana y Sergio se especializan en dise√±ar y mantener la infraestructura de datos, asegurando que la informaci√≥n sea accesible, eficiente y escalable para proyectos de alta complejidad. | **Felipe Dedes y Greta Combold** <br> Felipe y Greta lideran el desarrollo de modelos predictivos e implementan soluciones de machine learning que automatizan procesos y generan sistemas inteligentes con impacto real. |

## Juntos, combinamos nuestras habilidades para transformar datos en valor, aportando innovaci√≥n y resultados¬†efectivos.
***

[‚¨ÜÔ∏è Volver al √≠ndice](#√≠ndice)

*** 

![image](https://github.com/user-attachments/assets/90ce882b-4b85-495b-b972-8d3883f69bfa)
¬®
# üîçüìäEntendimiento de la situaci√≥n actual
_"El mercado de cafeter√≠as boutique y brunch est√° en pleno auge. La creciente demanda por experiencias gastron√≥micas √∫nicas y la b√∫squeda de ambientes acogedores lo convierten en un sector atractivo, pero tambi√©n competitivo.
Sin embargo, los principales desaf√≠os para la expansi√≥n incluyen:

1- Identificar zonas con alta demanda potencial.

2- Evaluar la rentabilidad proyectada en cada ubicaci√≥n.

3- Reducir riesgos asociados a la competencia y baja afluencia de p√∫blico.

A partir de estos puntos clave, hemos dise√±ado un an√°lisis que responde directamente a estas inquietudes y ofrece una gu√≠a estrat√©gica basada en datos."_

[‚¨ÜÔ∏è Volver al √≠ndice](#√≠ndice)

# üéØ‚ú®Objetivos 
![image](https://github.com/user-attachments/assets/75522d77-760b-42c1-ac4b-d091ab9dc7af)

###### Objetivo Espec√≠ficos:
1. **Realizar un An√°lisis Exploratorio de los Datos disponibles en Yelp y Google maps (incluir
aqu√≠ la otra fuente de dato si aplica)**
2. **Realizar un ETL que permita integrar datos de diversas fuentes y transformarlos en una
estructura unificada.**
3. **Definir el pipeline**
4. **Realizar el despliegue de datos en nube que facilite la ingesta de datos y alimentar el
modelo de machine learning.**
5. **Desarrollar un modelo de machine learning para predecir las oportunidades de inversi√≥n
basadas en los KPIs definidos.**
6. **Elaborar un dashboard de los KPIs e informaci√≥n clave de consulta.**

[‚¨ÜÔ∏è Volver al √≠ndice](#√≠ndice)


# üìèüåçAlcance
![image](https://github.com/user-attachments/assets/77078868-bc06-43e7-8441-68e18f3bb3ef)

 
Este proyecto se centra en realizar un an√°lisis integral del mercado para apoyar la expansi√≥n estrat√©gica del negocio 'Coffee & Brunch Business'. Consideramos los siguientes puntos clave dentro del alcance:
1. Recopilaci√≥n y procesamiento de datos provenientes de Yelp, Google Maps y otras fuentes relevantes.
2. Dise√±o e implementaci√≥n de un ETL para integrar y estructurar los datos en un formato unificado.
3. Identificaci√≥n de zonas de alto potencial mediante an√°lisis geoespacial y evaluaci√≥n de m√©tricas clave.
4. Desarrollo de un modelo predictivo de machine learning para estimar oportunidades de inversi√≥n.
5. Creaci√≥n de un dashboard interactivo para la visualizaci√≥n de KPIs e insights relevantes.
Este alcance est√° dise√±ado para ofrecer resultados accionables y maximizar el retorno de inversi√≥n, aline√°ndose con los objetivos de crecimiento del negocio.

ALCANCE Este proyecto incluir√° el an√°lisis y limpieza de datos disponibles en Yelp y Google Maps para negocios de cofee and breakfast en Estados Unidos, la elaboraci√≥n de un dashboard interactivo con la visualizaci√≥n de datos claves y Kpi y la implementaci√≥n de un modelo de machine learning para predicciones y recomendaciones sobre la expansi√≥n de este tipo de negocio.
Este proyecto no incluye la Integraci√≥n en tiempo real con las plataformas Yelp o google maps, an√°lisis de informaci√≥n por fuera de Estados Unidos ni tampoco estrateg√≠as de marketing de expansi√≥n que se puede desarrollar en una siguiente etapa.

[‚¨ÜÔ∏è Volver al √≠ndice](#√≠ndice)
***
![image](https://github.com/user-attachments/assets/ffc4470f-6ecf-4bfc-93a7-85bf48843901)

# üìàüîé EDA: An√°lisis Exploratorio de Datos
"En estas dos primeras semanas, nos enfocamos en recopilar, limpiar y analizar datos de Google Maps y Yelp. Nuestro EDA inicial incluye:
Demograf√≠a y densidad poblacional: Identificar zonas con alta concentraci√≥n de poblaci√≥n objetivo.
Tr√°fico peatonal: Evaluar la afluencia promedio en las √°reas seleccionadas.
Competencia: Mapear la presencia de negocios similares.
Presentaremos gr√°ficos claros que reflejen tanto los datos generales como los resultados despu√©s de la limpieza. Por ejemplo, visualizaremos las √°reas con mayor potencial versus las que presentan riesgos asociados a la saturaci√≥n del mercado."
![image](https://github.com/user-attachments/assets/ed9d7354-6ee9-415d-9fe0-f09b934d5852)
Para la base de datos de YELP encontramos alrededor de 150 mil comercios, los cuales se encuentran ubicados en 1416 ciudades de estados unidos, y como nos muestra el primer gr√°fico se encuentran mayormente concentrados en la ciudad de philadelphia con un 9.7%, Tucson con un 6.15% y tampa con un 6%.
Como el negocio objetivo del cliente son los negocios dedicados al comercio de Coffee & Tea y Breakfast and brunch, el segundo gr√°fico nos muestra la cantidad de negocios en estas categor√≠as.Para este caso contamos con 11.758 negocios de estas categor√≠as ubicados en un total de 616 ciudades de Estados Unidos, y como podemos observar, la mayor parte de estos negocios los podemos encontrar, en philadelphia, tampa, new Orleans, Tucson y Nashville. Siento Philadelphia la ciudad con m√°s negocios de este tipo en Estados Unidos.

![image](https://github.com/user-attachments/assets/d1505e48-0341-4e81-9717-a33843231fc7)
En los datos de YELP tambi√©n encontramos un poco m√°s de 7 millones de rese√±as escritas por los usuarios, de las cuales 1.147.000 corresponden a rese√±as de la categor√≠a Coffee and Breakfast.
En el gr√°fico de color azul, podemos ver la concentraci√≥n de estas rese√±as por ciudades, mostrando que en Philadelphia y New Orleans se encuentran la mayor cantidad de rese√±as del todo el dataset.

Y, por √∫ltimo, tenemos un gr√°fico que nos muestra la cantidad de usuarios que han dejado rese√±as en este tipo de comercios. 
Tenemos 574.000 usuarios con rese√±as en las 616 ciudades, mostrando la mayor concentraci√≥n de estos en Philadelphia, seguido por Tampa, New Orleans e Indianapolis.
Mostrando a Philadelphia como un gran destino para este tipo de negocios.

![image](https://github.com/user-attachments/assets/29ff9ab1-5e8d-4b39-b0a1-a97a406a9053)
![image](https://github.com/user-attachments/assets/f80f2792-daf3-4045-b0ee-c53144117cce)
Para el dataset de google se analizaron un total 2,9 millones de negocios y 89.9 millones de reviews para el periodo de tiempo que conlleva desde abril-2002 hasta septiembre-2021.
Se identificaron un total de 4461 categor√≠as distintas, de las cuales se tomaron las 50 categor√≠as de comida m√°s relevantes, que representan m√°s del 90% de los reviews totales asociados a establecimientos de comida.

Wordcloud: Se extrajo las palabras con mayor aparici√≥n dentro de las 50 categor√≠as top y se produjo el siguiente wordcloud. Aqu√≠ logramos identificar que las palabras m√°s relevantes son:  "fast," "food", "takeout‚Äù, ‚Äúpizza‚Äù, ‚Äúcoffee‚Äù, ‚Äòcafe‚Äô.

Rating Medio Categor√≠as: Teniendo en cuenta esto, calculamos el rating promedio de las categor√≠as y observamos que los establecimientos asociados a Coffee presentan un rating mucho m√°s elevado, en contraste con los locales de comida r√°pida, que se encuentran entre los peores calificados.

Establecimientos Unicos por Periodo: Despues de acotar nuestro locales a categorias asociadas a Coffee shops, evaluamos la presencia de establecimientos dentro de los reviews con una frecuencia trimestral. De esta manera, observamos que el sector se encuentra en crecimiento, a excepci√≥n de un periodo de deca√≠da posiblemente asociado a la pandemia.

Rating promedio por periodo: A pesar de esta ca√≠da, notamos que el rating promedio de estos establecimientos ha ido en alza, lo que puede ser un indicador tanto de una mejora constante en el servicio debido a la competencia del sector, as√≠ como tambi√©n una mejor aceptaci√≥n del p√∫blico a este tipo de establecimientos.


Conclusi√≥n: "Coffee" y "shop" son t√©rminos destacados, lo que indica la popularidad de cafeter√≠as y lugares donde los consumidores buscan bebidas r√°pidas y espacios para socializar o trabajar. Esto es consistente con la cultura estadounidense, donde el caf√© ocupa un lugar central.

[‚¨ÜÔ∏è Volver al √≠ndice](#√≠ndice)
***

 # üìäüìèKPIs
 ![image](https://github.com/user-attachments/assets/4deac3ae-91b7-4b3b-90d1-95bd26fdfcc2)

KPIS
En un mercado competitivo, el crecimiento y la salud de un negocio dependen de decisiones fundamentadas en datos. Por ello, hemos dise√±ado un sistema de medici√≥n basado en indicadores clave de desempe√±o (KPIs) que nos permitir√°n rastrear y optimizar aspectos esenciales como la satisfacci√≥n del cliente, la visibilidad del negocio y la conversi√≥n hacia compras efectivas. Este enfoque, sustentado por tecnolog√≠a avanzada, buscar√° garantizar una gesti√≥n estrat√©gica y escalable. 
proponer objetivo de crecimiento y cuanto tiempo
KPI1:

Nombre:Tasa de crecimiento de comentarios positivos
Objetivo: Monitorear la satisfacci√≥n de los clientes y la salud de la marca.
M√©trica: ¬øEst√° creciendo el volumen de opiniones positivas sobre nuestro negocio?
Descripci√≥n: mide el porcentaje de crecimiento de la cantidad total de puntuaciones positivas con respecto al periodo inmediatamente anterior
 
F√≥rmula: % de crecimiento de comentarios positivos = [(Total comentarios positivos periodo actual - Total comentarios positivos periodo anterior) / Total de comentarios positivos periodo anterior] * 100
 
KPI2:
Nombre: Puntuaci√≥n promedio
Objetivo: Representar de forma cuantitativa la experiencia del cliente.
M√©trica: Promedio de calificaciones otorgadas por los usuarios.
Descripci√≥n: Mide la satisfacci√≥n de los clientes representada por medio de la  puntuaci√≥n que registran los usuarios para el negocio.

F√≥rmula: Puntaje promedio = Sumatoria total de los puntajes del periodo / Total usuarios que dejaron su calificaci√≥n en el periodo.
 
KPI3
Nombre: Tasa de crecimiento de las calificaciones
Objetivo: Incrementar la visibilidad del negocio atrayendo a m√°s clientes a dejar rese√±as.
M√©trica: ¬øCu√°nto crecen las rese√±as en cada periodo?
Descripci√≥n:  Medir el crecimiento de la cantidad de clientes que est√°n dejando rese√±as, lo que refleja la visibilidad del negocio.

F√≥rmula: % de crecimiento de comentarios de las calificaciones = [(Total comentarios periodo actual - Total comentarios periodo anterior) / Total de comentarios periodo anterior] * 100

Puntaje promedio = Sumatoria total de los puntajes del periodo / Total usuarios que dejaron su calificaci√≥n en el periodo.

[‚¨ÜÔ∏è Volver al √≠ndice](#√≠ndice)

## üõ†Ô∏èüíªStack Tecnol√≥gico
![Imagen de WhatsApp 2024-12-12 a las 15 21 29_82e29ee7](https://github.com/user-attachments/assets/b267e89d-98ee-4e1d-936c-bb9f57ccf953)
Para garantizar que estas m√©tricas se capturen, transformen y analicen eficientemente, implementaremos una arquitectura robusta de Data Warehouse y Machine Learning divididas en cuatro m√≥dulos, la extracci√≥n, transformaci√≥n, data warehouse y visualizaci√≥n y machine learning
Extracci√≥n: 
Se considerar√° la extracci√≥n de datos de diversas fuentes, y se realizar√° carga de forma local, as√≠ como tambi√©n extracci√≥n via web scrapping y APIs de ser necesario. (Por definir).
Transformaci√≥n:
Cloud Scheduler: Las tareas de extracci√≥n se automatizar√°n utilizando.
Cloud Functions: Programar scripts de transformaci√≥n simples, que no requieran mucho poder de procesamiento y sean r√°pidos. As√≠ como tambi√©n activar los procesos BigQuery y DataFlow.
BigQuery: Se encargar√° de realizar transformaciones de fuentes de datos de mayor tama√±o usando queries SQL.
DataFlow: Se encargar√° de procesar data que no pueda transformarse usando SQL especialmente la que se usar√° para el modelo de machine learning

Datawarehouse:
BigQuery: Se usar√° BigQuery tambi√©n como almac√©n de datos. Ventajas: Se evita cargar datos desde google cloud storage e incurrir en gastos de transferencia. Data lista para ser procesada por otras herramientas despu√©s del ETL.

Visualizaci√≥n y ML
Streamlit: Se har√° uso de streamlit para generar un dashboard interactivo, as√≠ como tambi√©n para realizar el deploy del modelo de ML.
Una vez dise√±ada la app de streamlit, esta se conteinerizar√° con Docker para que pueda ser deployada en la nube de GCloud.
Se har√° uso de tecnolog√≠as de cloud como, Cloud Container Registry, y Cloud Run para poder guardar y deployar el container.

[‚¨ÜÔ∏è Volver al √≠ndice](#√≠ndice)

# Flujo de Trabajo
# Pipeline 

## üìùüß© Metodolog√≠a de trabajo
![image](https://github.com/user-attachments/assets/06a7dbf2-a68d-4d93-9506-f11b931324e6)

"Para organizar nuestro trabajo y dirigir nuestros esfuerzos hacia nuestras metas, hemos elegido trabajar con metodolog√≠as √°giles bajo el marco de trabajo SCRUM. Este enfoque nos va a permitir mejorar la organizaci√≥n de tareas, fomentar la colaboraci√≥n entre los integrantes del equipo y adaptarnos r√°pidamente a los cambios, asegurando entregas continuas y alineadas con nuestros objetivos."
[‚¨ÜÔ∏è Volver al √≠ndice](#√≠ndice)

## ‚è≥üìÖCronograma General Gantt
![image](https://github.com/user-attachments/assets/168deebf-1e27-404d-83bc-728ebc353a4b)

Cronograma General: Hitos y Entregables
"El proyecto est√° dise√±ado para ser entregado en seis semanas, con presentaciones cada dos semanas.
Semana 1-2:
EDA inicial con datos de Google Maps y Yelp.
Gr√°ficos que muestren la informaci√≥n limpia y general.
Definici√≥n de KPIs y f√≥rmulas, junto con las metas iniciales.
Semana 3-4:
Implementaci√≥n de un modelo predictivo para analizar la rentabilidad de las zonas priorizadas.
Mapas interactivos que representen el an√°lisis geoespacial.
Semana 5-6:
Finalizaci√≥n del dashboard interactivo.
Presentaci√≥n de recomendaciones finales y conclusiones basadas en los KPIs.
Hitos:
Desarrollo de herramientas visuales.
Documentaci√≥n clara del an√°lisis.
Recomendaciones estrat√©gicas accionables."

![gantt](https://github.com/user-attachments/assets/e9c25815-c014-4e27-86af-31defa961134)

El cronograma general del proyecto se detalla a continuaci√≥n, dividido en secciones como inicio, an√°lisis, desarrollo y finalizaci√≥n. Utilizamos un diagrama de Gantt para visualizar el progreso de cada tarea.

```mermaid
gantt
    title Cronograma General del Proyecto
    dateFormat  YYYY-MM-DD
    section Sprint 1
    Contextualizar la problem√°tica    :done, b1, 2024-12-02, 2d
    Definiciones de objetivos y alcance  :done, a2, 2024-12-04, 1d
    Comprender los datos disponibles  :done, a2, 2024-12-04, 2d
    Definici√≥n de Stack Tecnol√≥gico  :done, a2, 2024-12-05, 3d
    EDA y ETL inicial  :done, a2, 2024-12-05, 6d
    Definici√≥n y KPIs  :done, a2, 2024-12-10, 3d
    Preparaci√≥n y ensayo de presentaci√≥n :done, a2, 2024-12-10, 4d
    section Sprint 2 
    ETL completo      :active, b1, 2024-12-06, 5d
    Pipeline y automatizaci√≥n            :b2, 2024-12-11, 3d
    Dise√±o del Datawarehouse          :b2, 2024-12-11, 3d
    Dise√±o del modelo ER          :b2, 2024-12-11, 3d
    MVP Machine Learning         :b2, 2024-12-11, 3d
    Documentaci√≥n        :b2, 2024-12-11, 3d
    Preparaci√≥n y Ensayo   :b2, 2024-12-11, 3d
    section Sprint 3 
    Dise√±o de Reportes/Dashboards           :c1, 2024-12-14, 7d
    KPIs                  :c2, 2024-12-21, 4d
    Modelo de Machine Learning  :c2, 2024-12-21, 4d
    Documentaci√≥n               :d1, 2024-12-25, 3d
    Preparaci√≥n y ensayo de presentaci√≥n       :d2, 2024-12-28, 1d
```
[‚¨ÜÔ∏è Volver al √≠ndice](#√≠ndice)

# üîóüìÇRepositorio Github
El proyecto est√° organizado en diferentes ramas que abordan an√°lisis, limpieza de datos y machine learning:

## Rama Principal (main) Sergio Castro
Descripci√≥n General
La rama principal contiene el proceso de ETL y la culminaci√≥n del An√°lisis Exploratorio de Datos (EDA) del dataset Google. Esta rama sirve como base principal del proyecto, consolidando el trabajo inicial sobre los datos.

### Estructura de la Rama
#### ETL-google.ipynb

Notebook que realiza el proceso ETL (Extracci√≥n, Transformaci√≥n y Carga) del dataset Google.
Contenido:
Extracci√≥n de datos crudos.
Transformaci√≥n: limpieza, eliminaci√≥n de valores nulos y duplicados.
Preparaci√≥n de los datos para su posterior an√°lisis y modelado.
Resultados finales del EDA, donde se exploran tendencias y caracter√≠sticas clave de los datos.
#### README.md

Archivo de documentaci√≥n que describe la estructura y prop√≥sito del proyecto

#### Objetivos de la Rama Sergio Castro 
Realizar la preparaci√≥n de datos con un proceso ETL sobre el dataset Google.
Culminar el An√°lisis Exploratorio de Datos (EDA) para comprender las tendencias y caracter√≠sticas principales del dataset.
Consolidar la base de datos lista para los siguientes an√°lisis y modelado.

## Rama Diana Moreno
### Descripci√≥n General
Esta rama contiene el an√°lisis exploratorio de datos (EDA) y el proceso de Extracci√≥n, Transformaci√≥n y Carga (ETL) del dataset Yelp. El objetivo es preparar y analizar los datos para su uso posterior en el proyecto.

### Estructura de la Rama
#### EDA-YELP.ipynb

Notebook que realiza la Exploraci√≥n de Datos (EDA) del dataset Yelp.
Contenido:
An√°lisis inicial de las caracter√≠sticas de los datos.
Identificaci√≥n de valores nulos, duplicados y distribuciones.
Visualizaci√≥n de patrones y tendencias.

#### ETL-YELP.ipynb

Notebook que implementa el proceso de Extracci√≥n, Transformaci√≥n y Carga (ETL) de los datos de Yelp.
Contenido:
Extracci√≥n de datos crudos.
Transformaci√≥n: limpieza, eliminaci√≥n de inconsistencias y creaci√≥n de nuevas variables.
Preparaci√≥n de los datos para an√°lisis o modelado.
Objetivos de la Rama
Realizar un an√°lisis exploratorio para entender la estructura y calidad del dataset Yelp.
Implementar un proceso de ETL para preparar los datos para futuros an√°lisis y modelado.

[‚¨ÜÔ∏è Volver al √≠ndice](#√≠ndice)

***
"Estamos convencidos de que este proyecto ser√° el punto de partida para la expansi√≥n exitosa de su negocio. Nuestro trabajo no solo busca identificar ubicaciones rentables, sino tambi√©n brindarle herramientas que faciliten decisiones basadas en datos s√≥lidos y confiables.
Hoy le presentamos los primeros resultados de este proceso. A medida que avancemos, le mostraremos m√°s hallazgos, siempre con la misi√≥n de maximizar su √©xito en este sector tan competitivo."

### Contacto:
#### Claudia Jara Ya√±ez:
Rol: Data Analyst
Github:https://github.com/claujara1975

Linkedin:

#### Saray Pacheco Ramos:
Rol: Data Analyst  
Github: https://github.com/ssaraypr

#### Sergio Castro: Limpieza y an√°lisis del dataset Google.
Rol: Data Engineer
Github:https://github.com/SDCaFlo

LinkedIn: 
#### Diana Moreno: Limpieza y an√°lisis del dataset Yelp.
Rol:  Data Engineer
Github: https://github.com/dianitafeliz

LinkedIn:
#### Felipe Dedes : Machine learning y despliegue.
Rol: Machine Learning Engineer
Github:https://github.com/DedesF

LinkedIn:
#### Greta Combold: Machine Learning y despliegue.
Rol: Machine Learning Engineer
Github: https://github.com/PerlaMarGreta

LinkedIn:

[‚¨ÜÔ∏è Volver al √≠ndice](#√≠ndice)
